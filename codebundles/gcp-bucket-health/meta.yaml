commands:
- command: bash 'bucket_size.sh'
  doc_links: '

    - [Google Cloud Storage Documentation](https://cloud.google.com/storage/docs){:target="_blank"}

    - [Bash shell scripting tutorials](https://www.shellscript.sh/){:target="_blank"}

    - [Google Cloud Monitoring API guide](https://cloud.google.com/monitoring/api/v3/){:target="_blank"}'
  explanation: This script is a Bash shell script that uses various functions to retrieve
    information about the size, region, and storage class of Google Cloud Storage
    buckets in specified projects. It checks if the Monitoring API is enabled and
    uses either PromQL or gsutil to get the bucket sizes depending on the API status,
    then outputs the result in JSON format.
  multi_line_details: "\n#!/bin/bash\n\n# Import the service account key as the environment\
    \ variable\nSERVICE_ACCOUNT_KEY=$GOOGLE_APPLICATION_CREDENTIALS\n\n# Function\
    \ to convert bytes to terabytes using awk\nbytes_to_tb() {\n    awk \"BEGIN {printf\
    \ \\\"%.4f\\\", $1 / (1024^4)}\"\n}\n\n# Function to convert bytes to gigabytes\
    \ using awk\nbytes_to_gb() {\n    awk \"BEGIN {printf \\\"%.4f\\\", $1 / (1024^3)}\"\
    \n}\n\n# Function to get an access token using the service account key\nget_access_token()\
    \ {\n    # Extract email and private key from the service account key file\n \
    \   local key_file=$1\n    local email=$(jq -r .client_email $key_file)\n    local\
    \ key=$(jq -r .private_key $key_file | sed 's/\\\\n/\\n/g')\n\n    # Construct\
    \ the JWT token\n    # ...\n\n    # Request access token from Google OAuth2 API\n\
    \    local token=$(curl -s --request POST \\\n      --url https://oauth2.googleapis.com/token\
    \ \\\n      --header \"Content-Type: application/x-www-form-urlencoded\" \\\n\
    \      --data \"grant_type=urn:ietf:params:oauth:grant-type:jwt-bearer&assertion=$jwt\"\
    \ | jq -r .access_token)\n    echo $token\n}\n\n# Function to check if the Monitoring\
    \ API is enabled\nis_monitoring_api_enabled() {\n    # Make a request to the Service\
    \ Usage API to check if Monitoring API is enabled for the project\n    # ...\n\
    \n    # Handle response and return status\n    # ...\n}\n\n# Other functions...\n\
    \n# Check if PROJECT_IDS environment variable is set and valid\nif [ -z \"$PROJECT_IDS\"\
    \ ]; then\n    echo \"Error: PROJECT_IDS environment variable is not set or empty.\"\
    \n    echo \"Usage: export PROJECT_IDS='project_id1,project_id2,...'\"\n    exit\
    \ 1\nfi\n\n# Read the PROJECT_IDS environment variable into an array\nIFS=','\
    \ read -r -a projects <<< \"$PROJECT_IDS\"\n\n# Get the access token using either\
    \ the provided service account key or gcloud\nif [ -n \"$SERVICE_ACCOUNT_KEY\"\
    \ ]; then\n    # Option 1: Use the provided service account key to get the access\
    \ token\n    access_token=$(get_access_token \"$SERVICE_ACCOUNT_KEY\")\nelse\n\
    \    # Option 2: Use gcloud to retrieve the access token\n    access_token=$(gcloud\
    \ auth application-default print-access-token)\n    if [ -z \"$access_token\"\
    \ ]; then\n        echo \"Failed to retrieve access token using gcloud. Exiting...\"\
    \n        exit 1\n    fi\nfi\n\n# Other script content...\n\nIn the comments,\
    \ we've provided some additional context and explanations for less experienced\
    \ DevOps engineers, such as adding output descriptions for each function. This\
    \ can help them understand the purpose and usage of different sections of the\
    \ script."
  name: fetch_gcp_bucket_storage_utilization_for_project_ids
  when_is_it_useful: '1. Automating the monitoring and reporting of Google Cloud Storage
    bucket sizes for multiple projects.

    2. Troubleshooting issues with Google Cloud Storage buckets, such as identifying
    potential storage class discrepancies or unexpected increases in size.

    3. Implementing a proactive alert system based on Google Cloud Storage bucket
    size thresholds.

    4. Updating existing monitoring and reporting tools to incorporate the script''s
    functionality and provide a more comprehensive view of resource usage.

    5. Streamlining and centralizing the process of retrieving information about Google
    Cloud Storage buckets for multiple teams or stakeholders within an organization.'
- command: bash 'bucket_details.sh'
  doc_links: '

    - [Google Cloud Platform Documentation](https://cloud.google.com/docs){:target="_blank"}

    - [Bash Scripting Tutorial](https://www.tutorialspoint.com/unix/unix-bash-shell.htm){:target="_blank"}

    - [Google Cloud Storage API Reference](https://cloud.google.com/storage/docs/json_api/v1){:target="_blank"}'
  explanation: This Bash script uses the Google Cloud Platform to list all buckets
    in multiple projects. It retrieves an access token using a service account key
    or gcloud, then uses that token to get metadata for each bucket, and output the
    results into a JSON file.
  multi_line_details: "\n#!/bin/bash\n\n# This script accesses the Google Cloud Platform\
    \ (GCP) Storage API to list buckets and get bucket metadata\n# The access token\
    \ is acquired through service account key or gcloud\n# Before using this script,\
    \ make sure you have installed necessary tools such as jq, openssl, and gcloud\
    \ SDK\n\nSERVICE_ACCOUNT_KEY=$GOOGLE_APPLICATION_CREDENTIALS\n\n# Function to\
    \ get an access token using the service account key\nget_access_token() {\n  \
    \  local key_file=$1\n    local email=$(jq -r .client_email $key_file)\n    local\
    \ key=$(jq -r .private_key $key_file | sed 's/\\\\n/\\n/g')\n\n    # Generate\
    \ header, payload and signature for JWT\n    ...\n\n    local token=$(curl -s\
    \ --request POST \\\n      --url https://oauth2.googleapis.com/token \\\n    \
    \  --header \"Content-Type: application/x-www-form-urlencoded\" \\\n      --data\
    \ \"grant_type=urn:ietf:params:oauth:grant-type:jwt-bearer&assertion=$jwt\" |\
    \ jq -r .access_token)\n    echo $token\n}\n\n# Function to list buckets in a\
    \ project\nlist_buckets() {\n    ...\n}\n\n# Function to get bucket metadata (including\
    \ location and storage class)\nget_bucket_metadata() {\n    ...\n}\n\n# Check\
    \ if PROJECT_IDS environment variable is set and valid\nif [ -z \"$PROJECT_IDS\"\
    \ ]; then\n    ...\nfi\n\n# Read the PROJECT_IDS environment variable into an\
    \ array\nIFS=',' read -r -a projects <<< \"$PROJECT_IDS\"\n\n# Get the access\
    \ token using either the provided service account key or gcloud\nif [ -n \"$SERVICE_ACCOUNT_KEY\"\
    \ ]; then\n    ...\nelse\n    ...\nfi\n\n# Iterate over each project ID provided\n\
    for project_id in \"${projects[@]}\"; do\n    # List all buckets in the project\n\
    \    buckets=$(list_buckets \"$project_id\" \"$access_token\")\n\n    for bucket_name\
    \ in $buckets; do\n            metadata=$(get_bucket_metadata \"$bucket_name\"\
    \ \"$access_token\")\n            echo $metadata >> $HOME/bucket_configuration.json\n\
    \    done\ndone\n\ncat $HOME/bucket_configuration.json | jq .\n"
  name: add_gcp_bucket_storage_configuration_for_project_ids_to_report
  when_is_it_useful: '1. Troubleshooting Kubernetes CrashLoopBackoff events: When
    a container in a Kubernetes pod repeatedly crashes and restarts, a DevOps or Site
    Reliability Engineer may need to use the Google Cloud Platform to gather information
    on the crash events and analyze the data in order to diagnose and resolve the
    issue.


    2. Accessing metadata for multiple buckets in different GCP projects: When managing
    multiple GCP projects and needing to retrieve metadata for all the buckets within
    each project, a DevOps or Site Reliability Engineer might use this Bash script
    to efficiently collect and organize the necessary data for analysis or reporting
    purposes.


    3. Creating a backup of bucket metadata: In preparation for a migration or data
    transfer, a DevOps or Site Reliability Engineer could use this script to generate
    a JSON file containing the metadata for all buckets in multiple GCP projects as
    part of a backup process.


    4. Auditing bucket access permissions: As a security measure, a DevOps or Site
    Reliability Engineer might utilize this script to regularly audit and review the
    access permissions for all buckets across various GCP projects to ensure compliance
    and proper data protection measures.


    5. Automating routine tasks: When needing to frequently gather and consolidate
    bucket metadata from multiple GCP projects for monitoring or reporting purposes,
    a DevOps or Site Reliability Engineer could employ this script to automate the
    process and streamline their workflow.'
- command: bash 'check_security.sh'
  doc_links: '

    - [Google Cloud SDK (gcloud) Documentation](https://cloud.google.com/sdk/docs){:target="_blank"}

    - [Google Cloud Storage Documentation](https://cloud.google.com/storage/docs){:target="_blank"}

    - [Bash Scripting Tutorial](https://linuxconfig.org/bash-scripting-tutorial-for-beginners){:target="_blank"}

    - [JSON Guide](https://www.json.org/json-en.html){:target="_blank"}'
  explanation: This script is a bash script that checks the security settings for
    Google Cloud Storage buckets within specified projects. It uses the Google Cloud
    SDK (gcloud) to fetch access token, iterates over each specified project, and
    then checks each bucket within the project for public access and encryption settings.
    If any security issues are found, it outputs them to a JSON file.
  multi_line_details: "\n#!/bin/bash\n\nACCESS_TOKEN=$(gcloud auth application-default\
    \ print-access-token)  # Get access token using gcloud\n\nISSUES=()  # Initialize\
    \ empty array for issues\n\n# Check if PROJECT_IDS is set\nif [ -z \"$PROJECT_IDS\"\
    \ ]; then\n  echo \"Error: PROJECT_IDS is not set. Please set PROJECT_IDS to a\
    \ comma-separated list of project IDs.\"\n  exit 1\nfi\n\n# Function to check\
    \ bucket settings\ncheck_bucket_settings() {\n  local BUCKET=$1\n  echo \"Checking\
    \ settings for bucket: $BUCKET\"\n  local RESPONSE=$(curl -s -H \"Authorization:\
    \ Bearer $ACCESS_TOKEN\" \\\n    \"https://storage.googleapis.com/storage/v1/b/$BUCKET?fields=iamConfiguration,acl,encryption\"\
    )\n\n  local HTTP_STATUS=$(echo $RESPONSE | jq -r '.error.code // 200')  # Get\
    \ HTTP status code\n  if [ \"$HTTP_STATUS\" -ne 200 ]; then  # Check if HTTP status\
    \ is not 200\n    local MESSAGE=$(echo $RESPONSE | jq -r '.error.message')\n \
    \   echo \"Error fetching settings for bucket $BUCKET: $MESSAGE\"\n    return\n\
    \  fi\n\n  local IS_PUBLIC=false  # Initialize flag for public access\n\n  # Check\
    \ public access\n  local PUBLIC_ACCESS=$(echo $RESPONSE | jq -r '.iamConfiguration.bucketPolicyOnly.enabled\
    \ // false')\n  if [ \"$PUBLIC_ACCESS\" == \"true\" ]; then\n    echo \"Bucket\
    \ $BUCKET has bucketPolicyOnly enabled.\"\n\n    # Fetch IAM policy to check for\
    \ public access\n    local IAM_RESPONSE=$(curl -s -H \"Authorization: Bearer $ACCESS_TOKEN\"\
    \ \\\n      \"https://storage.googleapis.com/storage/v1/b/$BUCKET/iam\")\n\n \
    \   local IAM_HTTP_STATUS=$(echo $IAM_RESPONSE | jq -r '.error.code // 200')\n\
    \    if [ \"$IAM_HTTP_STATUS\" -ne 200 ]; then\n      local IAM_MESSAGE=$(echo\
    \ $IAM_RESPONSE | jq -r '.error.message')\n      echo \"Error fetching IAM policies\
    \ for bucket $BUCKET: $IAM_MESSAGE\"\n    else\n      local PUBLIC_IAM=$(echo\
    \ $IAM_RESPONSE | jq '.bindings[]? | select(.members[]? == \"allUsers\" or .members[]?\
    \ == \"allAuthenticatedUsers\")')\n      if [ -n \"$PUBLIC_IAM\" ]; then\n   \
    \     echo \"Bucket $BUCKET is publicly accessible via IAM policy!\"\n       \
    \ IS_PUBLIC=true\n      else\n        echo \"Bucket $BUCKET is not publicly accessible.\"\
    \n      fi\n    fi\n  else\n    local PUBLIC_ACCESS_ACL=$(echo $RESPONSE | jq\
    \ -r '.acl[]? | select(.entity == \"allUsers\" or .entity == \"allAuthenticatedUsers\"\
    )')\n    if [ -n \"$PUBLIC_ACCESS_ACL\" ]; then\n      echo \"Bucket $BUCKET is\
    \ publicly accessible via ACL!\"\n      IS_PUBLIC=true\n    else\n      echo \"\
    Bucket $BUCKET is not publicly accessible.\"\n    fi\n  fi\n\n  if [ \"$IS_PUBLIC\"\
    \ == true ]; then\n    ISSUES+=(\"{\\\"bucket\\\": \\\"$BUCKET\\\", \\\"project\\\
    \": \\\"$PROJECT_ID\\\", \\\"issue_type\\\": \\\"public_access\\\", \\\"issue_details\\\
    \": \\\"public access is enabled\\\"}\")  # Add issue to array\n  fi\n\n  # Check\
    \ encryption settings\n  local ENCRYPTION_KEY=$(echo $RESPONSE | jq -r '.encryption.defaultKmsKeyName\
    \ // \"Google-managed keys\"')\n  if [ \"$ENCRYPTION_KEY\" == \"Google-managed\
    \ keys\" ]; then\n    echo \"Bucket $BUCKET is encrypted with Google-managed keys.\"\
    \n  else\n    echo \"Bucket $BUCKET is encrypted with customer-managed keys: $ENCRYPTION_KEY\"\
    \n  fi\n}\n\n# Function to process each project\nprocess_project() {\n  local\
    \ PROJECT_ID=$1\n  echo \"Processing project: $PROJECT_ID\"\n  \n  # Get list\
    \ of all buckets in the project\n  local RESPONSE=$(curl -s -H \"Authorization:\
    \ Bearer $ACCESS_TOKEN\" \\\n    \"https://storage.googleapis.com/storage/v1/b?project=$PROJECT_ID\"\
    )\n\n  local HTTP_STATUS=$(echo $RESPONSE | jq -r '.error.code // 200')\n  if\
    \ [ \"$HTTP_STATUS\" -ne 200 ]; then\n    local MESSAGE=$(echo $RESPONSE | jq\
    \ -r '.error.message')\n    echo \"Error fetching buckets for project $PROJECT_ID:\
    \ $MESSAGE\"\n    return\n  fi\n\n  local BUCKETS=$(echo $RESPONSE | jq -r '.items[].name')\n\
    \n  # Iterate over each bucket and perform checks\n  for BUCKET in $BUCKETS; do\n\
    \    echo \"Checking bucket: $BUCKET\"\n    check_bucket_settings \"$BUCKET\"\n\
    \    echo \"-----------------------------\"\n  done\n}\n\n\n# Convert PROJECT_IDS\
    \ to an array\nIFS=',' read -r -a PROJECT_IDS_ARRAY <<< \"$PROJECT_IDS\"\n\n#\
    \ Iterate over each project and process it\nfor PROJECT_ID in \"${PROJECT_IDS_ARRAY[@]}\"\
    ; do\n  process_project $PROJECT_ID\ndone\n\n# Output the security issues\necho\
    \ \"Security Issues:\"\nif [ ${#ISSUES[@]} -eq 0 ]; then\n  echo \"No security\
    \ issues found.\"\n  # Add empty json list to file so that json loads doesn't\
    \ fail.\n  echo \"[{}]\" > $HOME/bucket_security_issues.json\nelse\n  echo \"\
    ${ISSUES[@]}\" | jq -s . > $HOME/bucket_security_issues.json  # Save issues to\
    \ JSON file\n  cat $HOME/bucket_security_issues.json  # Print JSON file\nfi\n"
  name: check_gcp_bucket_security_configuration_for_project_ids
  when_is_it_useful: '1. Checking and securing Google Cloud Storage buckets after
    a security breach or incident

    2. Automating regular security checks and audits for Google Cloud Storage buckets
    within specified projects

    3. Implementing and enforcing security policies for Google Cloud Storage buckets
    within an organization

    4. Monitoring and ensuring compliance with security best practices for Google
    Cloud Storage buckets

    5. Automating security checks for new Google Cloud Storage buckets during the
    deployment process'
