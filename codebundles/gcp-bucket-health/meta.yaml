commands:
- command: bash 'bucket_size.sh'
  doc_links: '

    - [Google Cloud Storage Documentation](https://cloud.google.com/storage/docs){:target="_blank"}

    - [Bash shell scripting tutorials](https://www.shellscript.sh/){:target="_blank"}

    - [Google Cloud Monitoring API guide](https://cloud.google.com/monitoring/api/v3/){:target="_blank"}'
  explanation: This script is a Bash shell script that uses various functions to retrieve
    information about the size, region, and storage class of Google Cloud Storage
    buckets in specified projects. It checks if the Monitoring API is enabled and
    uses either PromQL or gsutil to get the bucket sizes depending on the API status,
    then outputs the result in JSON format.
  multi_line_details: "\n#!/bin/bash\n\n# Import the service account key as the environment\
    \ variable\nSERVICE_ACCOUNT_KEY=$GOOGLE_APPLICATION_CREDENTIALS\n\n# Function\
    \ to convert bytes to terabytes using awk\nbytes_to_tb() {\n    awk \"BEGIN {printf\
    \ \\\"%.4f\\\", $1 / (1024^4)}\"\n}\n\n# Function to convert bytes to gigabytes\
    \ using awk\nbytes_to_gb() {\n    awk \"BEGIN {printf \\\"%.4f\\\", $1 / (1024^3)}\"\
    \n}\n\n# Function to get an access token using the service account key\nget_access_token()\
    \ {\n    # Extract email and private key from the service account key file\n \
    \   local key_file=$1\n    local email=$(jq -r .client_email $key_file)\n    local\
    \ key=$(jq -r .private_key $key_file | sed 's/\\\\n/\\n/g')\n\n    # Construct\
    \ the JWT token\n    # ...\n\n    # Request access token from Google OAuth2 API\n\
    \    local token=$(curl -s --request POST \\\n      --url https://oauth2.googleapis.com/token\
    \ \\\n      --header \"Content-Type: application/x-www-form-urlencoded\" \\\n\
    \      --data \"grant_type=urn:ietf:params:oauth:grant-type:jwt-bearer&assertion=$jwt\"\
    \ | jq -r .access_token)\n    echo $token\n}\n\n# Function to check if the Monitoring\
    \ API is enabled\nis_monitoring_api_enabled() {\n    # Make a request to the Service\
    \ Usage API to check if Monitoring API is enabled for the project\n    # ...\n\
    \n    # Handle response and return status\n    # ...\n}\n\n# Other functions...\n\
    \n# Check if PROJECT_IDS environment variable is set and valid\nif [ -z \"$PROJECT_IDS\"\
    \ ]; then\n    echo \"Error: PROJECT_IDS environment variable is not set or empty.\"\
    \n    echo \"Usage: export PROJECT_IDS='project_id1,project_id2,...'\"\n    exit\
    \ 1\nfi\n\n# Read the PROJECT_IDS environment variable into an array\nIFS=','\
    \ read -r -a projects <<< \"$PROJECT_IDS\"\n\n# Get the access token using either\
    \ the provided service account key or gcloud\nif [ -n \"$SERVICE_ACCOUNT_KEY\"\
    \ ]; then\n    # Option 1: Use the provided service account key to get the access\
    \ token\n    access_token=$(get_access_token \"$SERVICE_ACCOUNT_KEY\")\nelse\n\
    \    # Option 2: Use gcloud to retrieve the access token\n    access_token=$(gcloud\
    \ auth application-default print-access-token)\n    if [ -z \"$access_token\"\
    \ ]; then\n        echo \"Failed to retrieve access token using gcloud. Exiting...\"\
    \n        exit 1\n    fi\nfi\n\n# Other script content...\n\nIn the comments,\
    \ we've provided some additional context and explanations for less experienced\
    \ DevOps engineers, such as adding output descriptions for each function. This\
    \ can help them understand the purpose and usage of different sections of the\
    \ script."
  name: fetch_gcp_bucket_storage_utilization_for_project_ids
  when_is_it_useful: '1. Automating the monitoring and reporting of Google Cloud Storage
    bucket sizes for multiple projects.

    2. Troubleshooting issues with Google Cloud Storage buckets, such as identifying
    potential storage class discrepancies or unexpected increases in size.

    3. Implementing a proactive alert system based on Google Cloud Storage bucket
    size thresholds.

    4. Updating existing monitoring and reporting tools to incorporate the script''s
    functionality and provide a more comprehensive view of resource usage.

    5. Streamlining and centralizing the process of retrieving information about Google
    Cloud Storage buckets for multiple teams or stakeholders within an organization.'
- command: bash 'bucket_details.sh'
  doc_links: '

    - [Google Cloud Platform Documentation](https://cloud.google.com/docs){:target="_blank"}

    - [Bash Scripting Tutorial](https://www.tutorialspoint.com/unix/unix-bash-shell.htm){:target="_blank"}

    - [Google Cloud Storage API Reference](https://cloud.google.com/storage/docs/json_api/v1){:target="_blank"}'
  explanation: This Bash script uses the Google Cloud Platform to list all buckets
    in multiple projects. It retrieves an access token using a service account key
    or gcloud, then uses that token to get metadata for each bucket, and output the
    results into a JSON file.
  multi_line_details: "\n#!/bin/bash\n\n# This script accesses the Google Cloud Platform\
    \ (GCP) Storage API to list buckets and get bucket metadata\n# The access token\
    \ is acquired through service account key or gcloud\n# Before using this script,\
    \ make sure you have installed necessary tools such as jq, openssl, and gcloud\
    \ SDK\n\nSERVICE_ACCOUNT_KEY=$GOOGLE_APPLICATION_CREDENTIALS\n\n# Function to\
    \ get an access token using the service account key\nget_access_token() {\n  \
    \  local key_file=$1\n    local email=$(jq -r .client_email $key_file)\n    local\
    \ key=$(jq -r .private_key $key_file | sed 's/\\\\n/\\n/g')\n\n    # Generate\
    \ header, payload and signature for JWT\n    ...\n\n    local token=$(curl -s\
    \ --request POST \\\n      --url https://oauth2.googleapis.com/token \\\n    \
    \  --header \"Content-Type: application/x-www-form-urlencoded\" \\\n      --data\
    \ \"grant_type=urn:ietf:params:oauth:grant-type:jwt-bearer&assertion=$jwt\" |\
    \ jq -r .access_token)\n    echo $token\n}\n\n# Function to list buckets in a\
    \ project\nlist_buckets() {\n    ...\n}\n\n# Function to get bucket metadata (including\
    \ location and storage class)\nget_bucket_metadata() {\n    ...\n}\n\n# Check\
    \ if PROJECT_IDS environment variable is set and valid\nif [ -z \"$PROJECT_IDS\"\
    \ ]; then\n    ...\nfi\n\n# Read the PROJECT_IDS environment variable into an\
    \ array\nIFS=',' read -r -a projects <<< \"$PROJECT_IDS\"\n\n# Get the access\
    \ token using either the provided service account key or gcloud\nif [ -n \"$SERVICE_ACCOUNT_KEY\"\
    \ ]; then\n    ...\nelse\n    ...\nfi\n\n# Iterate over each project ID provided\n\
    for project_id in \"${projects[@]}\"; do\n    # List all buckets in the project\n\
    \    buckets=$(list_buckets \"$project_id\" \"$access_token\")\n\n    for bucket_name\
    \ in $buckets; do\n            metadata=$(get_bucket_metadata \"$bucket_name\"\
    \ \"$access_token\")\n            echo $metadata >> $HOME/bucket_configuration.json\n\
    \    done\ndone\n\ncat $HOME/bucket_configuration.json | jq .\n"
  name: add_gcp_bucket_storage_configuration_for_project_ids_to_report
  when_is_it_useful: '1. Troubleshooting Kubernetes CrashLoopBackoff events: When
    a container in a Kubernetes pod repeatedly crashes and restarts, a DevOps or Site
    Reliability Engineer may need to use the Google Cloud Platform to gather information
    on the crash events and analyze the data in order to diagnose and resolve the
    issue.


    2. Accessing metadata for multiple buckets in different GCP projects: When managing
    multiple GCP projects and needing to retrieve metadata for all the buckets within
    each project, a DevOps or Site Reliability Engineer might use this Bash script
    to efficiently collect and organize the necessary data for analysis or reporting
    purposes.


    3. Creating a backup of bucket metadata: In preparation for a migration or data
    transfer, a DevOps or Site Reliability Engineer could use this script to generate
    a JSON file containing the metadata for all buckets in multiple GCP projects as
    part of a backup process.


    4. Auditing bucket access permissions: As a security measure, a DevOps or Site
    Reliability Engineer might utilize this script to regularly audit and review the
    access permissions for all buckets across various GCP projects to ensure compliance
    and proper data protection measures.


    5. Automating routine tasks: When needing to frequently gather and consolidate
    bucket metadata from multiple GCP projects for monitoring or reporting purposes,
    a DevOps or Site Reliability Engineer could employ this script to automate the
    process and streamline their workflow.'
- command: bash 'check_security.sh'
  doc_links: '

    - [gcloud command line tool documentation](https://cloud.google.com/sdk/gcloud){:target="_blank"}

    - [curl command documentation](https://curl.se/docs/){:target="_blank"}'
  explanation: This script is a Bash script that checks the security settings of Google
    Cloud Storage buckets within specified projects. It uses the gcloud command line
    tool and the curl command to make requests to the Google Cloud Storage API, and
    then reports any security issues found.
  multi_line_details: "\n#!/bin/bash\n\nACCESS_TOKEN=$(gcloud auth application-default\
    \ print-access-token) # Retrieving access token using gcloud command\n\n# Array\
    \ to store issues found during the script execution\nISSUES=()\n\n# Check if PROJECT_IDS\
    \ is set\nif [ -z \"$PROJECT_IDS\" ]; then\n  echo \"Error: PROJECT_IDS is not\
    \ set. Please set PROJECT_IDS to a comma-separated list of project IDs.\"\n  exit\
    \ 1\nfi\n\n# Function to check bucket settings\ncheck_bucket_settings() {\n  local\
    \ BUCKET=$1\n  echo \"Checking settings for bucket: $BUCKET\"\n  \n  local RESPONSE=$(curl\
    \ -s -H \"Authorization: Bearer $ACCESS_TOKEN\" \\\n    \"https://storage.googleapis.com/storage/v1/b/$BUCKET?fields=iamConfiguration,acl,encryption\"\
    )\n\n  local HTTP_STATUS=$(echo $RESPONSE | jq -r '.error.code // 200') # Checking\
    \ HTTP status of the response\n  if [ \"$HTTP_STATUS\" -ne 200 ]; then\n    local\
    \ MESSAGE=$(echo $RESPONSE | jq -r '.error.message')\n    echo \"Error fetching\
    \ settings for bucket $BUCKET: $MESSAGE\"\n    return\n  fi\n\n  local IS_PUBLIC=false\n\
    \n  # Check public access\n  local PUBLIC_ACCESS=$(echo $RESPONSE | jq -r '.iamConfiguration.bucketPolicyOnly.enabled\
    \ // false') # Checking if bucketPolicyOnly is enabled\n  if [ \"$PUBLIC_ACCESS\"\
    \ == \"true\" ]; then\n    echo \"Bucket $BUCKET has bucketPolicyOnly enabled.\"\
    \n\n    # Fetch IAM policy to check for public access\n    local IAM_RESPONSE=$(curl\
    \ -s -H \"Authorization: Bearer $ACCESS_TOKEN\" \\\n      \"https://storage.googleapis.com/storage/v1/b/$BUCKET/iam\"\
    )\n\n    local IAM_HTTP_STATUS=$(echo $IAM_RESPONSE | jq -r '.error.code // 200')\n\
    \    if [ \"$IAM_HTTP_STATUS\" -ne 200 ]; then\n      local IAM_MESSAGE=$(echo\
    \ $IAM_RESPONSE | jq -r '.error.message')\n      echo \"Error fetching IAM policies\
    \ for bucket $BUCKET: $IAM_MESSAGE\"\n    else\n      local PUBLIC_IAM=$(echo\
    \ $IAM_RESPONSE | jq '.bindings[]? | select(.members[]? == \"allUsers\" or .members[]?\
    \ == \"allAuthenticatedUsers\")')\n      if [ -n \"$PUBLIC_IAM\" ]; then\n   \
    \     echo \"Bucket $BUCKET is publicly accessible via IAM policy!\"\n       \
    \ IS_PUBLIC=true\n      else\n        echo \"Bucket $BUCKET is not publicly accessible.\"\
    \n      fi\n    fi\n  else\n    local PUBLIC_ACCESS_ACL=$(echo $RESPONSE | jq\
    \ -r '.acl[]? | select(.entity == \"allUsers\" or .entity == \"allAuthenticatedUsers\"\
    )')\n    if [ -n \"$PUBLIC_ACCESS_ACL\" ]; then\n      echo \"Bucket $BUCKET is\
    \ publicly accessible via ACL!\"\n      IS_PUBLIC=true\n    else\n      echo \"\
    Bucket $BUCKET is not publicly accessible.\"\n    fi\n  fi\n\n  if [ \"$IS_PUBLIC\"\
    \ == true ]; then\n    ISSUES+=(\"{\\\"bucket\\\": \\\"$BUCKET\\\", \\\"project\\\
    \": \\\"$PROJECT_ID\\\", \\\"issue_type\\\": \\\"public_access\\\", \\\"issue_details\\\
    \": \\\"public access is enabled\\\"}\") # Adding issue to the ISSUES array\n\
    \  fi\n\n  # Check encryption settings\n  local ENCRYPTION_KEY=$(echo $RESPONSE\
    \ | jq -r '.encryption.defaultKmsKeyName // \"Google-managed keys\"')\n  if [\
    \ \"$ENCRYPTION_KEY\" == \"Google-managed keys\" ]; then\n    echo \"Bucket $BUCKET\
    \ is encrypted with Google-managed keys.\"\n  else\n    echo \"Bucket $BUCKET\
    \ is encrypted with customer-managed keys: $ENCRYPTION_KEY\"\n  fi\n}\n\n# Function\
    \ to process each project\nprocess_project() {\n  local PROJECT_ID=$1\n  echo\
    \ \"Processing project: $PROJECT_ID\"\n  \n  # Get list of all buckets in the\
    \ project\n  local RESPONSE=$(curl -s -H \"Authorization: Bearer $ACCESS_TOKEN\"\
    \ \\\n    \"https://storage.googleapis.com/storage/v1/b?project=$PROJECT_ID\"\
    )\n\n  local HTTP_STATUS=$(echo $RESPONSE | jq -r '.error.code // 200') # Checking\
    \ HTTP status of the response\n  if [ \"$HTTP_STATUS\" -ne 200 ]; then\n    local\
    \ MESSAGE=$(echo $RESPONSE | jq -r '.error.message')\n    echo \"Error fetching\
    \ buckets for project $PROJECT_ID: $MESSAGE\"\n    return\n  fi\n\n  local BUCKETS=$(echo\
    \ $RESPONSE | jq -r '.items[].name')\n\n  # Iterate over each bucket and perform\
    \ checks\n  for BUCKET in $BUCKETS; do\n    echo \"Checking bucket: $BUCKET\"\n\
    \    check_bucket_settings \"$BUCKET\" # Calling function to check bucket settings\n\
    \    echo \"-----------------------------\"\n  done\n}\n\n# Convert PROJECT_IDS\
    \ to an array\nIFS=',' read -r -a PROJECT_IDS_ARRAY <<< \"$PROJECT_IDS\"\n\n#\
    \ Iterate over each project and process it\nfor PROJECT_ID in \"${PROJECT_IDS_ARRAY[@]}\"\
    ; do\n  process_project $PROJECT_ID # Calling function to process each project\n\
    done\n\n# Output the security issues\necho \"Security Issues:\"\nif [ ${#ISSUES[@]}\
    \ -eq 0 ]; then\n  echo \"No security issues found.\"\nelse\n  echo \"${ISSUES[@]}\"\
    \ | jq -s . > $HOME/bucket_security_issues.json # Converting the ISSUES array\
    \ to JSON and saving it to a file\n  cat $HOME/bucket_security_issues.json\nfi\n"
  name: check_gcp_bucket_security_configuration_for_project_ids
  when_is_it_useful: '1. Performing regular security audits on Google Cloud Storage
    buckets to ensure compliance with company and industry security standards.

    2. Conducting post-deployment checks after making changes to Google Cloud Storage
    bucket security settings to confirm that the changes were successful and did not
    introduce any new security vulnerabilities.

    3. Investigating security incidents or breaches involving Google Cloud Storage
    buckets to identify any potential security weaknesses or misconfigurations that
    may have been exploited.

    4. Automating the process of checking Google Cloud Storage bucket security settings
    as part of a continuous monitoring and alerting framework to proactively detect
    and address any potential security risks.

    5. Assisting in the development of security best practices and guidelines for
    configuring and managing Google Cloud Storage buckets, and ensuring adherence
    to these standards across all projects within the organization.'
