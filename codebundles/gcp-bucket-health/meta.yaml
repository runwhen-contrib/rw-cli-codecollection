commands:
- command: bash 'bucket_size.sh'
  doc_links: '

    - [Google Cloud Storage Documentation](https://cloud.google.com/storage/docs){:target="_blank"}

    - [Bash shell scripting tutorials](https://www.shellscript.sh/){:target="_blank"}

    - [Google Cloud Monitoring API guide](https://cloud.google.com/monitoring/api/v3/){:target="_blank"}'
  explanation: This script is a Bash shell script that uses various functions to retrieve
    information about the size, region, and storage class of Google Cloud Storage
    buckets in specified projects. It checks if the Monitoring API is enabled and
    uses either PromQL or gsutil to get the bucket sizes depending on the API status,
    then outputs the result in JSON format.
  multi_line_details: "\n#!/bin/bash\n\n# Import the service account key as the environment\
    \ variable\nSERVICE_ACCOUNT_KEY=$GOOGLE_APPLICATION_CREDENTIALS\n\n# Function\
    \ to convert bytes to terabytes using awk\nbytes_to_tb() {\n    awk \"BEGIN {printf\
    \ \\\"%.4f\\\", $1 / (1024^4)}\"\n}\n\n# Function to convert bytes to gigabytes\
    \ using awk\nbytes_to_gb() {\n    awk \"BEGIN {printf \\\"%.4f\\\", $1 / (1024^3)}\"\
    \n}\n\n# Function to get an access token using the service account key\nget_access_token()\
    \ {\n    # Extract email and private key from the service account key file\n \
    \   local key_file=$1\n    local email=$(jq -r .client_email $key_file)\n    local\
    \ key=$(jq -r .private_key $key_file | sed 's/\\\\n/\\n/g')\n\n    # Construct\
    \ the JWT token\n    # ...\n\n    # Request access token from Google OAuth2 API\n\
    \    local token=$(curl -s --request POST \\\n      --url https://oauth2.googleapis.com/token\
    \ \\\n      --header \"Content-Type: application/x-www-form-urlencoded\" \\\n\
    \      --data \"grant_type=urn:ietf:params:oauth:grant-type:jwt-bearer&assertion=$jwt\"\
    \ | jq -r .access_token)\n    echo $token\n}\n\n# Function to check if the Monitoring\
    \ API is enabled\nis_monitoring_api_enabled() {\n    # Make a request to the Service\
    \ Usage API to check if Monitoring API is enabled for the project\n    # ...\n\
    \n    # Handle response and return status\n    # ...\n}\n\n# Other functions...\n\
    \n# Check if PROJECT_IDS environment variable is set and valid\nif [ -z \"$PROJECT_IDS\"\
    \ ]; then\n    echo \"Error: PROJECT_IDS environment variable is not set or empty.\"\
    \n    echo \"Usage: export PROJECT_IDS='project_id1,project_id2,...'\"\n    exit\
    \ 1\nfi\n\n# Read the PROJECT_IDS environment variable into an array\nIFS=','\
    \ read -r -a projects <<< \"$PROJECT_IDS\"\n\n# Get the access token using either\
    \ the provided service account key or gcloud\nif [ -n \"$SERVICE_ACCOUNT_KEY\"\
    \ ]; then\n    # Option 1: Use the provided service account key to get the access\
    \ token\n    access_token=$(get_access_token \"$SERVICE_ACCOUNT_KEY\")\nelse\n\
    \    # Option 2: Use gcloud to retrieve the access token\n    access_token=$(gcloud\
    \ auth application-default print-access-token)\n    if [ -z \"$access_token\"\
    \ ]; then\n        echo \"Failed to retrieve access token using gcloud. Exiting...\"\
    \n        exit 1\n    fi\nfi\n\n# Other script content...\n\nIn the comments,\
    \ we've provided some additional context and explanations for less experienced\
    \ DevOps engineers, such as adding output descriptions for each function. This\
    \ can help them understand the purpose and usage of different sections of the\
    \ script."
  name: fetch_gcp_bucket_storage_utilization_for_project_ids
  when_is_it_useful: '1. Automating the monitoring and reporting of Google Cloud Storage
    bucket sizes for multiple projects.

    2. Troubleshooting issues with Google Cloud Storage buckets, such as identifying
    potential storage class discrepancies or unexpected increases in size.

    3. Implementing a proactive alert system based on Google Cloud Storage bucket
    size thresholds.

    4. Updating existing monitoring and reporting tools to incorporate the script''s
    functionality and provide a more comprehensive view of resource usage.

    5. Streamlining and centralizing the process of retrieving information about Google
    Cloud Storage buckets for multiple teams or stakeholders within an organization.'
- command: bash 'bucket_details.sh'
  doc_links: '

    - [Google Cloud Platform Documentation](https://cloud.google.com/docs){:target="_blank"}

    - [Bash Scripting Tutorial](https://www.tutorialspoint.com/unix/unix-bash-shell.htm){:target="_blank"}

    - [Google Cloud Storage API Reference](https://cloud.google.com/storage/docs/json_api/v1){:target="_blank"}'
  explanation: This Bash script uses the Google Cloud Platform to list all buckets
    in multiple projects. It retrieves an access token using a service account key
    or gcloud, then uses that token to get metadata for each bucket, and output the
    results into a JSON file.
  multi_line_details: "\n#!/bin/bash\n\n# This script accesses the Google Cloud Platform\
    \ (GCP) Storage API to list buckets and get bucket metadata\n# The access token\
    \ is acquired through service account key or gcloud\n# Before using this script,\
    \ make sure you have installed necessary tools such as jq, openssl, and gcloud\
    \ SDK\n\nSERVICE_ACCOUNT_KEY=$GOOGLE_APPLICATION_CREDENTIALS\n\n# Function to\
    \ get an access token using the service account key\nget_access_token() {\n  \
    \  local key_file=$1\n    local email=$(jq -r .client_email $key_file)\n    local\
    \ key=$(jq -r .private_key $key_file | sed 's/\\\\n/\\n/g')\n\n    # Generate\
    \ header, payload and signature for JWT\n    ...\n\n    local token=$(curl -s\
    \ --request POST \\\n      --url https://oauth2.googleapis.com/token \\\n    \
    \  --header \"Content-Type: application/x-www-form-urlencoded\" \\\n      --data\
    \ \"grant_type=urn:ietf:params:oauth:grant-type:jwt-bearer&assertion=$jwt\" |\
    \ jq -r .access_token)\n    echo $token\n}\n\n# Function to list buckets in a\
    \ project\nlist_buckets() {\n    ...\n}\n\n# Function to get bucket metadata (including\
    \ location and storage class)\nget_bucket_metadata() {\n    ...\n}\n\n# Check\
    \ if PROJECT_IDS environment variable is set and valid\nif [ -z \"$PROJECT_IDS\"\
    \ ]; then\n    ...\nfi\n\n# Read the PROJECT_IDS environment variable into an\
    \ array\nIFS=',' read -r -a projects <<< \"$PROJECT_IDS\"\n\n# Get the access\
    \ token using either the provided service account key or gcloud\nif [ -n \"$SERVICE_ACCOUNT_KEY\"\
    \ ]; then\n    ...\nelse\n    ...\nfi\n\n# Iterate over each project ID provided\n\
    for project_id in \"${projects[@]}\"; do\n    # List all buckets in the project\n\
    \    buckets=$(list_buckets \"$project_id\" \"$access_token\")\n\n    for bucket_name\
    \ in $buckets; do\n            metadata=$(get_bucket_metadata \"$bucket_name\"\
    \ \"$access_token\")\n            echo $metadata >> $HOME/bucket_configuration.json\n\
    \    done\ndone\n\ncat $HOME/bucket_configuration.json | jq .\n"
  name: add_gcp_bucket_storage_configuration_for_project_ids_to_report
  when_is_it_useful: '1. Troubleshooting Kubernetes CrashLoopBackoff events: When
    a container in a Kubernetes pod repeatedly crashes and restarts, a DevOps or Site
    Reliability Engineer may need to use the Google Cloud Platform to gather information
    on the crash events and analyze the data in order to diagnose and resolve the
    issue.


    2. Accessing metadata for multiple buckets in different GCP projects: When managing
    multiple GCP projects and needing to retrieve metadata for all the buckets within
    each project, a DevOps or Site Reliability Engineer might use this Bash script
    to efficiently collect and organize the necessary data for analysis or reporting
    purposes.


    3. Creating a backup of bucket metadata: In preparation for a migration or data
    transfer, a DevOps or Site Reliability Engineer could use this script to generate
    a JSON file containing the metadata for all buckets in multiple GCP projects as
    part of a backup process.


    4. Auditing bucket access permissions: As a security measure, a DevOps or Site
    Reliability Engineer might utilize this script to regularly audit and review the
    access permissions for all buckets across various GCP projects to ensure compliance
    and proper data protection measures.


    5. Automating routine tasks: When needing to frequently gather and consolidate
    bucket metadata from multiple GCP projects for monitoring or reporting purposes,
    a DevOps or Site Reliability Engineer could employ this script to automate the
    process and streamline their workflow.'
- command: bash 'check_security.sh'
  doc_links: '

    - [Google Cloud SDK (gcloud) Documentation](https://cloud.google.com/sdk/docs){:target="_blank"}

    - [Google Cloud Storage Documentation](https://cloud.google.com/storage/docs){:target="_blank"}

    - [Bash Scripting Tutorial](https://linuxconfig.org/bash-scripting-tutorial-for-beginners){:target="_blank"}

    - [JSON Guide](https://www.json.org/json-en.html){:target="_blank"}'
  explanation: This script is a bash script that checks the security settings for
    Google Cloud Storage buckets within specified projects. It uses the Google Cloud
    SDK (gcloud) to fetch access token, iterates over each specified project, and
    then checks each bucket within the project for public access and encryption settings.
    If any security issues are found, it outputs them to a JSON file.
  multi_line_details: "\n#!/bin/bash\n\nACCESS_TOKEN=$(gcloud auth application-default\
    \ print-access-token)  # Get access token using gcloud\n\nISSUES=()  # Initialize\
    \ empty array for issues\n\n# Check if PROJECT_IDS is set\nif [ -z \"$PROJECT_IDS\"\
    \ ]; then\n  echo \"Error: PROJECT_IDS is not set. Please set PROJECT_IDS to a\
    \ comma-separated list of project IDs.\"\n  exit 1\nfi\n\n# Function to check\
    \ bucket settings\ncheck_bucket_settings() {\n  local BUCKET=$1\n  echo \"Checking\
    \ settings for bucket: $BUCKET\"\n  local RESPONSE=$(curl -s -H \"Authorization:\
    \ Bearer $ACCESS_TOKEN\" \\\n    \"https://storage.googleapis.com/storage/v1/b/$BUCKET?fields=iamConfiguration,acl,encryption\"\
    )\n\n  local HTTP_STATUS=$(echo $RESPONSE | jq -r '.error.code // 200')  # Get\
    \ HTTP status code\n  if [ \"$HTTP_STATUS\" -ne 200 ]; then  # Check if HTTP status\
    \ is not 200\n    local MESSAGE=$(echo $RESPONSE | jq -r '.error.message')\n \
    \   echo \"Error fetching settings for bucket $BUCKET: $MESSAGE\"\n    return\n\
    \  fi\n\n  local IS_PUBLIC=false  # Initialize flag for public access\n\n  # Check\
    \ public access\n  local PUBLIC_ACCESS=$(echo $RESPONSE | jq -r '.iamConfiguration.bucketPolicyOnly.enabled\
    \ // false')\n  if [ \"$PUBLIC_ACCESS\" == \"true\" ]; then\n    echo \"Bucket\
    \ $BUCKET has bucketPolicyOnly enabled.\"\n\n    # Fetch IAM policy to check for\
    \ public access\n    local IAM_RESPONSE=$(curl -s -H \"Authorization: Bearer $ACCESS_TOKEN\"\
    \ \\\n      \"https://storage.googleapis.com/storage/v1/b/$BUCKET/iam\")\n\n \
    \   local IAM_HTTP_STATUS=$(echo $IAM_RESPONSE | jq -r '.error.code // 200')\n\
    \    if [ \"$IAM_HTTP_STATUS\" -ne 200 ]; then\n      local IAM_MESSAGE=$(echo\
    \ $IAM_RESPONSE | jq -r '.error.message')\n      echo \"Error fetching IAM policies\
    \ for bucket $BUCKET: $IAM_MESSAGE\"\n    else\n      local PUBLIC_IAM=$(echo\
    \ $IAM_RESPONSE | jq '.bindings[]? | select(.members[]? == \"allUsers\" or .members[]?\
    \ == \"allAuthenticatedUsers\")')\n      if [ -n \"$PUBLIC_IAM\" ]; then\n   \
    \     echo \"Bucket $BUCKET is publicly accessible via IAM policy!\"\n       \
    \ IS_PUBLIC=true\n      else\n        echo \"Bucket $BUCKET is not publicly accessible.\"\
    \n      fi\n    fi\n  else\n    local PUBLIC_ACCESS_ACL=$(echo $RESPONSE | jq\
    \ -r '.acl[]? | select(.entity == \"allUsers\" or .entity == \"allAuthenticatedUsers\"\
    )')\n    if [ -n \"$PUBLIC_ACCESS_ACL\" ]; then\n      echo \"Bucket $BUCKET is\
    \ publicly accessible via ACL!\"\n      IS_PUBLIC=true\n    else\n      echo \"\
    Bucket $BUCKET is not publicly accessible.\"\n    fi\n  fi\n\n  if [ \"$IS_PUBLIC\"\
    \ == true ]; then\n    ISSUES+=(\"{\\\"bucket\\\": \\\"$BUCKET\\\", \\\"project\\\
    \": \\\"$PROJECT_ID\\\", \\\"issue_type\\\": \\\"public_access\\\", \\\"issue_details\\\
    \": \\\"public access is enabled\\\"}\")  # Add issue to array\n  fi\n\n  # Check\
    \ encryption settings\n  local ENCRYPTION_KEY=$(echo $RESPONSE | jq -r '.encryption.defaultKmsKeyName\
    \ // \"Google-managed keys\"')\n  if [ \"$ENCRYPTION_KEY\" == \"Google-managed\
    \ keys\" ]; then\n    echo \"Bucket $BUCKET is encrypted with Google-managed keys.\"\
    \n  else\n    echo \"Bucket $BUCKET is encrypted with customer-managed keys: $ENCRYPTION_KEY\"\
    \n  fi\n}\n\n# Function to process each project\nprocess_project() {\n  local\
    \ PROJECT_ID=$1\n  echo \"Processing project: $PROJECT_ID\"\n  \n  # Get list\
    \ of all buckets in the project\n  local RESPONSE=$(curl -s -H \"Authorization:\
    \ Bearer $ACCESS_TOKEN\" \\\n    \"https://storage.googleapis.com/storage/v1/b?project=$PROJECT_ID\"\
    )\n\n  local HTTP_STATUS=$(echo $RESPONSE | jq -r '.error.code // 200')\n  if\
    \ [ \"$HTTP_STATUS\" -ne 200 ]; then\n    local MESSAGE=$(echo $RESPONSE | jq\
    \ -r '.error.message')\n    echo \"Error fetching buckets for project $PROJECT_ID:\
    \ $MESSAGE\"\n    return\n  fi\n\n  local BUCKETS=$(echo $RESPONSE | jq -r '.items[].name')\n\
    \n  # Iterate over each bucket and perform checks\n  for BUCKET in $BUCKETS; do\n\
    \    echo \"Checking bucket: $BUCKET\"\n    check_bucket_settings \"$BUCKET\"\n\
    \    echo \"-----------------------------\"\n  done\n}\n\n\n# Convert PROJECT_IDS\
    \ to an array\nIFS=',' read -r -a PROJECT_IDS_ARRAY <<< \"$PROJECT_IDS\"\n\n#\
    \ Iterate over each project and process it\nfor PROJECT_ID in \"${PROJECT_IDS_ARRAY[@]}\"\
    ; do\n  process_project $PROJECT_ID\ndone\n\n# Output the security issues\necho\
    \ \"Security Issues:\"\nif [ ${#ISSUES[@]} -eq 0 ]; then\n  echo \"No security\
    \ issues found.\"\n  # Add empty json list to file so that json loads doesn't\
    \ fail.\n  echo \"[{}]\" > $HOME/bucket_security_issues.json\nelse\n  echo \"\
    ${ISSUES[@]}\" | jq -s . > $HOME/bucket_security_issues.json  # Save issues to\
    \ JSON file\n  cat $HOME/bucket_security_issues.json  # Print JSON file\nfi\n"
  name: check_gcp_bucket_security_configuration_for_project_ids
  when_is_it_useful: '1. Checking and securing Google Cloud Storage buckets after
    a security breach or incident

    2. Automating regular security checks and audits for Google Cloud Storage buckets
    within specified projects

    3. Implementing and enforcing security policies for Google Cloud Storage buckets
    within an organization

    4. Monitoring and ensuring compliance with security best practices for Google
    Cloud Storage buckets

    5. Automating security checks for new Google Cloud Storage buckets during the
    deployment process'
- command: bash 'bucket_ops_costs.sh'
  doc_links: '

    - [Google Cloud Platform APIs](https://cloud.google.com/apis){:target="_blank"}

    - [Monitoring API](https://cloud.google.com/monitoring/api/v3){:target="_blank"}

    - [Google Cloud Storage API - List Objects](https://cloud.google.com/storage/docs/listing-objects){:target="_blank"}

    - [PromQL (Prometheus Query Language)](https://prometheus.io/docs/prometheus/latest/querying/basics/){:target="_blank"}'
  explanation: This script is a bash shell script that uses Google Cloud Platform
    APIs to get access tokens, check if the Monitoring API is enabled for certain
    projects, list buckets in a project, and get the sizes of all buckets using PromQL.
    It then outputs the results in JSON format.
  multi_line_details: "\n#!/bin/bash\n\nSERVICE_ACCOUNT_KEY=$GOOGLE_APPLICATION_CREDENTIALS\n\
    # Function to get an access token using the service account key\nget_access_token()\
    \ {\n    local key_file=$1\n    local email=$(jq -r .client_email $key_file)\n\
    \    local key=$(jq -r .private_key $key_file | sed 's/\\\\n/\\n/g')\n\n    local\
    \ header=$(echo -n '{\"alg\":\"RS256\",\"typ\":\"JWT\"}' | openssl base64 -e -A\
    \ | tr -d '=' | tr '/+' '_-' | tr -d '\\n')\n    local now=$(date +%s)\n    local\
    \ exp=$(($now + 3600))\n    local payload=$(echo -n \"{\\\"iss\\\":\\\"$email\\\
    \",\\\"scope\\\":\\\"https://www.googleapis.com/auth/cloud-platform\\\",\\\"aud\\\
    \":\\\"https://oauth2.googleapis.com/token\\\",\\\"exp\\\":$exp,\\\"iat\\\":$now}\"\
    \ | openssl base64 -e -A | tr -d '=' | tr '/+' '_-' | tr -d '\\n')\n\n    local\
    \ sig=$(echo -n \"$header.$payload\" | openssl dgst -sha256 -sign <(echo -n \"\
    $key\") | openssl base64 -e -A | tr -d '=' | tr '/+' '_-' | tr -d '\\n')\n\n \
    \   local jwt=\"$header.$payload.$sig\"\n\n    local token=$(curl -s --request\
    \ POST \\\n      --url https://oauth2.googleapis.com/token \\\n      --header\
    \ \"Content-Type: application/x-www-form-urlencoded\" \\\n      --data \"grant_type=urn:ietf:params:oauth:grant-type:jwt-bearer&assertion=$jwt\"\
    \ | jq -r .access_token)\n    echo $token\n}\n\n# Function to check if the Monitoring\
    \ API is enabled\nis_monitoring_api_enabled() {\n    local project_id=$1\n   \
    \ local token=$2\n    local response=$(curl -s -w \"\\nHTTP_STATUS:%{http_code}\"\
    \ --header \"Authorization: Bearer $token\" \\\n        \"https://serviceusage.googleapis.com/v1/projects/$project_id/services/monitoring.googleapis.com\"\
    )\n\n    local http_status=$(echo \"$response\" | sed -n 's/.*HTTP_STATUS:\\([0-9]*\\\
    )$/\\1/p')\n    local response_body=$(echo \"$response\" | sed -n '1,/^HTTP_STATUS:/p'\
    \ | sed '$d')\n\n    if [[ \"$http_status\" -ne 200 ]]; then\n        echo \"\
    Error checking Monitoring API status for project $project_id:\"\n        echo\
    \ \"HTTP Status: $http_status\"\n        echo \"Response: $response_body\"\n \
    \       return 1\n    fi\n\n    local state=$(echo \"$response_body\" | jq -r\
    \ '.state')\n    if [[ \"$state\" == \"ENABLED\" ]]; then\n        return 0\n\
    \    else\n        echo \"Monitoring API is not enabled for project $project_id.\"\
    \n        echo \"State: $state\"\n        return 1\n    fi\n}\n\n# Function to\
    \ list buckets in a project\nlist_buckets() {\n    local project_id=$1\n    local\
    \ token=$2\n    local response=$(curl -s --header \"Authorization: Bearer $token\"\
    \ \\\n        \"https://storage.googleapis.com/storage/v1/b?project=$project_id\"\
    )\n\n    echo $response | jq -r '.items[].name'\n}\n\n# Function to get the sizes\
    \ of all buckets using PromQL\nget_bucket_read_ops() {\n    local project_id=$1\n\
    \    local token=$2\n\n    local response=$(curl -s --header \"Authorization:\
    \ Bearer $token\" \\\n        --header \"Content-Type: application/x-www-form-urlencoded\"\
    \ \\\n        --data 'query=sum by (bucket_name)(rate(storage_googleapis_com:api_request_count{monitored_resource=\"\
    gcs_bucket\",method=~\"Read.*|List.*|Get.*\"}[30m]))' \\\n        \"https://monitoring.googleapis.com/v1/projects/$project_id/location/global/prometheus/api/v1/query\"\
    )\n\n    echo $response | jq -r '.data.result[] | {bucket_name: .metric.bucket_name,\
    \ ops: .value[1]}'\n}\n\n# Function to get the sizes of all buckets using PromQL\n\
    get_bucket_write_ops() {\n    local project_id=$1\n    local token=$2\n\n    local\
    \ response=$(curl -s --header \"Authorization: Bearer $token\" \\\n        --header\
    \ \"Content-Type: application/x-www-form-urlencoded\" \\\n        --data 'query=sum\
    \ by (bucket_name)(rate(storage_googleapis_com:api_request_count{monitored_resource=\"\
    gcs_bucket\",method=~\"Write.*\"}[30m]))' \\\n        \"https://monitoring.googleapis.com/v1/projects/$project_id/location/global/prometheus/api/v1/query\"\
    )\n\n    echo $response | jq -r '.data.result[] | {bucket_name: .metric.bucket_name,\
    \ ops: .value[1]}'\n}\n# Function to get bucket metadata (including location and\
    \ storage class)\nget_bucket_metadata() {\n    local bucket_name=$1\n    local\
    \ token=$2\n    local response=$(curl -s --header \"Authorization: Bearer $token\"\
    \ \\\n        \"https://storage.googleapis.com/storage/v1/b/$bucket_name\")\n\n\
    \    echo $response\n}\n\n# Check if PROJECT_IDS environment variable is set and\
    \ valid\nif [ -z \"$PROJECT_IDS\" ]; then\n    echo \"Error: PROJECT_IDS environment\
    \ variable is not set or empty.\"\n    echo \"Usage: export PROJECT_IDS='project_id1,project_id2,...'\"\
    \n    exit 1\nfi\n\n# Read the PROJECT_IDS environment variable into an array\n\
    IFS=',' read -r -a projects <<< \"$PROJECT_IDS\"\n\n# Get the access token using\
    \ either the provided service account key or gcloud\nif [ -n \"$SERVICE_ACCOUNT_KEY\"\
    \ ]; then\n    echo \"Using the SERVICE_ACCOUNT_KEY to get the access token.\"\
    \n    access_token=$(get_access_token \"$SERVICE_ACCOUNT_KEY\")\nelse\n    echo\
    \ \"SERVICE_ACCOUNT_KEY is not set. Attempting to set access token using gcloud.\"\
    \n    access_token=$(gcloud auth application-default print-access-token)\n   \
    \ if [ -z \"$access_token\" ]; then\n        echo \"Failed to retrieve access\
    \ token using gcloud. Exiting...\"\n        exit 1\n    fi\nfi\n\nread_ops=()\n\
    write_ops=()\n\n# Iterate over each project ID provided\nfor project_id in \"\
    ${projects[@]}\"; do\n    echo \"Processing project: $project_id\"\n\n    # List\
    \ all buckets in the project\n    buckets=$(list_buckets \"$project_id\" \"$access_token\"\
    )\n\n        # Iterate over each bucket and match its size\n    if is_monitoring_api_enabled\
    \ \"$project_id\" \"$access_token\"; then\n        echo \"Monitoring API is enabled\
    \ for project: $project_id\"\n\n        # Get the read/write operations of all\
    \ buckets\n        all_bucket_read_ops=$(get_bucket_read_ops \"$project_id\" \"\
    $access_token\")\n        all_bucket_write_ops=$(get_bucket_write_ops \"$project_id\"\
    \ \"$access_token\")\n\n        # Iterate over each bucket and match its size\n\
    \        for bucket_name in $buckets; do\n            echo \"Processing bucket:\
    \ $bucket_name\"\n            \n            # Initialize operations to zero\n\
    \            read_ops=0\n            write_ops=0\n\n            # Get the read/write\
    \ operations for the current bucket\n            read_ops=$(echo \"$all_bucket_read_ops\"\
    \ | jq -r --arg bucket_name \"$bucket_name\" '. | select(.bucket_name == $bucket_name)\
    \ | .ops // 0 | tonumber | round')\n            write_ops=$(echo \"$all_bucket_write_ops\"\
    \ | jq -r --arg bucket_name \"$bucket_name\" '. | select(.bucket_name == $bucket_name)\
    \ | .ops // 0 | tonumber | round')\n\n\n            # Calculate the total operations\
    \ and cost using jq for arithmetic\n            total_ops=$(echo \"$write_ops\
    \ $read_ops\" | jq -n '[inputs] | add')\n\n            # Print results\n     \
    \       echo \"Read Rate: $read_ops ops/s, Write Rate: $write_ops ops/s, Total\
    \ rate: $total_ops ops/s\"\n\n            # Get the region\n            region=$(echo\
    \ \"$metadata\" | jq -r '.location')\n\n            # Add bucket operations to\
    \ the list\n            bucket_ops+=(\"{\\\"project\\\": \\\"$project_id\\\",\
    \ \\\"bucket\\\": \\\"$bucket_name\\\", \\\"write_ops\\\": \\\"$write_ops\\\"\
    , \\\"read_ops\\\": \\\"$read_ops\\\", \\\"total_ops\\\": \\\"$total_ops\\\",\
    \ \\\"region\\\": \\\"$region\\\"}\")\n        done\n    else\n        echo \"\
    Monitoring API is not enabled for project: $project_id\"\n    fi\n\ndone\n\n#\
    \ Output the result in JSON format\necho \"[\"$(IFS=,; echo \"${bucket_ops[*]}\"\
    )\"]\" > $HOME/bucket_ops_report.json\ncat $HOME/bucket_ops_report.json | jq 'sort_by(.total_ops)\
    \ | reverse'\n\n"
  name: fetch_gcp_bucket_storage_operations_rate_for_project_ids
  when_is_it_useful: '1. Troubleshooting Kubernetes CrashLoopBackoff events: A DevOps
    or Site Reliability Engineer might use this script to gather monitoring data from
    Google Cloud Platform to investigate the cause of the CrashLoopBackoff events
    and identify any issues with the containers running in the Kubernetes cluster.


    2. Monitoring resource usage and performance: This script could be used to regularly
    collect data on resource usage and performance metrics from Google Cloud Platform,
    allowing DevOps or Site Reliability Engineers to analyze trends and identify potential
    bottlenecks or areas for optimization.


    3. Automating monitoring and reporting tasks: By using the script to access GCP
    APIs, DevOps or Site Reliability Engineers can automate the process of generating
    reports on resource usage, performance, and other key metrics, saving time and
    effort in monitoring and analysis tasks.


    4. Managing and analyzing cloud storage usage: The script can be utilized to list
    and retrieve information about buckets in a GCP project, enabling DevOps or Site
    Reliability Engineers to manage and analyze cloud storage usage more efficiently.


    5. Incident response and post-incident analysis: In the event of an incident or
    service disruption, the script can be used to quickly gather relevant monitoring
    data from GCP, aiding the investigation and post-incident analysis conducted by
    DevOps or Site Reliability Engineers.'
