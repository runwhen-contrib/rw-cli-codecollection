commands:
- command: kubectl logs deployment/${DEPLOYMENT_NAME} -n ${NAMESPACE} --tail=${LOG_LINES}
    --all-containers=true --max-log-requests=20 --context ${CONTEXT}
  doc_links: '

    - [Viewing and Filtering Logs](https://kubernetes.io/docs/concepts/cluster-administration/logging/){:target="_blank"}

    - [Kubectl Command Reference](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#logs){:target="_blank"}'
  explanation: This command is used to view the logs of a specific deployment in a
    Kubernetes cluster, allowing you to specify the number of log lines to display
    and the context in which to view the logs. It also includes options for displaying
    logs from all containers within the deployment and limiting the number of log
    requests.
  multi_line_details: '

    # Set the kubectl context to the specified cluster

    kubectl config use-context ${CONTEXT}


    # Display the logs for the specified deployment in the specified namespace

    # Limit the number of lines of output to ${LOG_LINES}

    # Include logs from all containers within the pod

    # Allow a maximum of 20 log requests to be made

    kubectl logs deployment/${DEPLOYMENT_NAME} -n ${NAMESPACE} --tail=${LOG_LINES}
    --all-containers=true --max-log-requests=20

    '
  name: fetch_deployments_logs_for_deployment_name_and_add_to_report
  when_is_it_useful: '1. Troubleshooting a Kubernetes CrashLoopBackoff event: The
    DevOps or Site Reliability Engineer may need to use this command to view the logs
    of the deployment to identify any errors or issues causing the pod to continuously
    restart.


    2. Monitoring application performance: The engineer may use this command to view
    the logs of a specific deployment to monitor the performance of the application
    and identify any bottlenecks or errors affecting its functionality.


    3. Investigating security incidents: In the event of a security incident or breach,
    the engineer may need to review the logs of a specific deployment to identify
    any unauthorized access or unusual activity within the Kubernetes cluster.


    4. Debugging an application issue: When troubleshooting an issue with a specific
    application running on the Kubernetes cluster, the engineer may use this command
    to view the logs and identify the root cause of the problem.


    5. Analyzing resource usage: The engineer may use this command to view the logs
    of a deployment to analyze the resource usage of the application and identify
    any inefficiencies or areas for optimization within the Kubernetes environment.'
- command: bash 'validate_probes.sh' livenessProbe | tee "${SCRIPT_TMP_DIR}/liveness_probe_output"
  doc_links: '

    - [Kubernetes Deployment Manifest](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/){:target="_blank"}

    - [Bash Scripting Tutorial](https://linuxconfig.org/bash-scripting-tutorial){:target="_blank"}

    - [Kubernetes Probes](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/){:target="_blank"}'
  explanation: This script is a Bash script that validates the configuration of probes
    in a Kubernetes deployment manifest. It checks if the ports used in the probe
    configurations are exposed by the containers and offers recommendations for next
    steps if any issues are found.
  multi_line_details: "\n#!/bin/bash\n\n# Set deployment name and namespace\nPROBE_TYPE=\"\
    ${1:-readinessProbe}\"  # Default to livenessProbe, can be set to readinessProbe\n\
    \n# Function to extract data using jq\nextract_data() {\n    echo \"$1\" | jq\
    \ -r \"$2\" 2>/dev/null  # jq used to extract data in JSON format\n}\n\n# Function\
    \ to extract port from command\nextract_port_from_command() {\n    echo \"$1\"\
    \ | grep -oE ':[0-9]+' | grep -oE '[0-9]+' | head -n 1  # regex used to extract\
    \ ports\n}\n\n# Get deployment manifest in JSON format\nMANIFEST=$(${KUBERNETES_DISTRIBUTION_BINARY}\
    \ get deployment \"$DEPLOYMENT_NAME\" -n \"$NAMESPACE\" --context \"$CONTEXT\"\
    \ -o json)  # Fetching deployment details using kubernetes distribution binary\
    \ \nif [ $? -ne 0 ]; then  # Check if error occurred while fetching deployment\
    \ details\n    echo \"Error fetching deployment details: $MANIFEST\"\n    exit\
    \ 1\nfi\n\n# Get number of containers\nNUM_CONTAINERS=$(extract_data \"$MANIFEST\"\
    \ '.spec.template.spec.containers | length')  # Extracting number of containers\n\
    if [ -z \"$NUM_CONTAINERS\" ]; then  # Check if no containers found\n    echo\
    \ \"No containers found in deployment.\"\n    exit 1\nfi\n\nnext_steps=()  # Initialize\
    \ empty array for next steps\n\n# Loop through containers and validate probes\n\
    for ((i=0; i<NUM_CONTAINERS; i++)); do\n    PROBE=$(extract_data \"$MANIFEST\"\
    \ \".spec.template.spec.containers[$i].${PROBE_TYPE}\")  # Extracting type of\
    \ probe for each container\n    CONTAINER_NAME=$(extract_data \"$MANIFEST\" \"\
    .spec.template.spec.containers[$i].name\")  # Extracting container name\n    echo\
    \ \"-------- START Validation - Container Name: $CONTAINER_NAME Probe Type: $PROBE_TYPE\
    \ -------\"\n    echo \"Container: \\`$CONTAINER_NAME\\`\"\n    echo \"$PROBE_TYPE:\
    \ $PROBE\"\n\n    # List container ports\n    CONTAINER_PORTS=$(extract_data \"\
    $MANIFEST\" \".spec.template.spec.containers[$i].ports[].containerPort\")  # Extracting\
    \ exposed ports for the container\n    if [ -n \"$CONTAINER_PORTS\" ]; then\n\
    \        echo \"Exposed Ports: $CONTAINER_PORTS\"\n    else:\n        echo \"\
    No ports exposed.\"\n    fi\n\n    if [ -z \"$PROBE\" ]; then  # Check if probe\
    \ not found for container\n        echo \"Container \\`$CONTAINER_NAME\\`: ${PROBE_TYPE}\
    \ not found.\"\n        continue\n    fi\n\n    # Validate that the port in the\
    \ probe is defined in the container's ports\n    if echo \"$PROBE\" | jq -e '.httpGet,\
    \ .tcpSocket' >/dev/null; then  # Check if HTTP GET or TCP Socket present\n  \
    \      PROBE_PORT=$(extract_data \"$PROBE\" '.httpGet.port // .tcpSocket.port')\
    \  # Extracting port for probe\n        CONTAINER_PORTS=$(extract_data \"$MANIFEST\"\
    \ \".spec.template.spec.containers[$i].ports[].containerPort\")  # Extracting\
    \ container ports\n\n        if [[ ! \" $CONTAINER_PORTS \" == *\"$PROBE_PORT\"\
    * ]]; then  # Check if probe port exists in container ports\n            echo\
    \ \"Container \\`$CONTAINER_NAME\\`: Port $PROBE_PORT used in $PROBE_TYPE is not\
    \ exposed by the container.\"\n            next_steps+=(\"Update $PROBE_TYPE For\
    \ \\`${DEPLOYMENT_NAME}\\` to use one of the following ports: $CONTAINER_PORTS\"\
    )\n        else:\n            echo \"Container \\`$CONTAINER_NAME\\`: ${PROBE_TYPE}\
    \ port $PROBE_PORT is valid.\"\n        fi\n    fi\n\n    # Check if exec permissions\
    \ are available (for exec type probes)\n    if echo \"$PROBE\" | jq -e '.exec'\
    \ >/dev/null; then  # Check if exec exists\n        IFS=$'\\n' read -r -d '' -a\
    \ EXEC_COMMAND_ARRAY < <(echo \"$PROBE\" | jq -r '.exec.command[]' && printf '\\\
    0')  # Extracting exec command\n        PORT_IN_COMMAND=$(extract_port_from_command\
    \ \"${EXEC_COMMAND_ARRAY[*]}\")  # Extracting port from exec command\n\n     \
    \   # Check if we see the port in the exec command, and if so, if it's defined\
    \ in the manifest\n        if [ -n \"$PORT_IN_COMMAND\" ]; then  # Check if port\
    \ exists in exec command\n            CONTAINER_PORTS=$(extract_data \"$MANIFEST\"\
    \ \".spec.template.spec.containers[$i].ports[].containerPort\")  # Extracting\
    \ container ports\n            if [[ ! \" $CONTAINER_PORTS \" == *\"$PORT_IN_COMMAND\"\
    * ]]; then  # Check if port exists in container ports\n                echo \"\
    Container \\`$CONTAINER_NAME\\`: Port $PORT_IN_COMMAND used in ${PROBE_TYPE} exec\
    \ command is not exposed by the container. The following ports are exposed: $CONTAINER_PORTS\"\
    \n                next_steps+=(\"Get Deployment Workload Details For \\`$DEPLOYMENT_NAME\\\
    `\")\n                next_steps+=(\"Remediate Readiness and Liveness Probes for\
    \ Deployments in Namespace \\`${NAMESPACE}\\`\")\n            else:\n        \
    \        echo \"Container \\`$CONTAINER_NAME\\`: Port $PORT_IN_COMMAND in ${PROBE_TYPE}\
    \ exec command is valid.\"\n            fi\n        fi\n\n        # Check exec\
    \ permission and execute command\n        if ${KUBERNETES_DISTRIBUTION_BINARY}\
    \ auth can-i create pods/exec -n \"$NAMESPACE\" >/dev/null 2>&1; then  # Check\
    \ exec permissions\n            # Execute command\n            # ...\n       \
    \     # ... (more code to execute command and test ports)\n\n        else\n  \
    \          echo \"Exec permission is not available.\"\n        fi\n    fi\n  \
    \  echo \"------- END Validation - Container Name: $CONTAINER_NAME Probe Type:\
    \ $PROBE_TYPE -------\"\ndone\n\n# Display all unique recommendations that can\
    \ be shown as Next Steps\nif [[ ${#next_steps[@]} -ne 0 ]]; then  # Check if there\
    \ are any next steps\n    printf \"\\nRecommended Next Steps: \\n\"\n    printf\
    \ \"%s\\n\" \"${next_steps[@]}\" | sort -u  # Print unique next steps\nfi\n"
  name: check_liveness_probe_configuration_for_deployment_deployment_name
  when_is_it_useful: '1. Deploying a new application or service to a Kubernetes cluster
    and wanting to ensure that the probes are correctly configured to monitor the
    health and readiness of the application.


    2. Troubleshooting ongoing issues with applications or services experiencing CrashLoopBackoff
    events within a Kubernetes cluster, and needing to verify if the probe configurations
    are contributing to the problem.


    3. Performing routine maintenance or updates on existing deployments in a Kubernetes
    cluster and wanting to ensure that all probe configurations are set up correctly
    before making any changes.


    4. Investigating performance issues within a Kubernetes cluster and wanting to
    validate the probe configurations for potential improvements in monitoring and
    managing the health of applications.


    5. Onboarding new team members or colleagues to work on managing Kubernetes deployments
    and wanting to provide a tool for them to easily validate and understand the probe
    configurations in deployment manifests.'
- command: bash 'validate_probes.sh' readinessProbe | tee "${SCRIPT_TMP_DIR}/readiness_probe_output"
  doc_links: '

    - [Kubernetes Deployment Manifest](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/){:target="_blank"}

    - [Bash Scripting Tutorial](https://linuxconfig.org/bash-scripting-tutorial){:target="_blank"}

    - [Kubernetes Probes](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/){:target="_blank"}'
  explanation: This script is a Bash script that validates the configuration of probes
    in a Kubernetes deployment manifest. It checks if the ports used in the probe
    configurations are exposed by the containers and offers recommendations for next
    steps if any issues are found.
  multi_line_details: "\n#!/bin/bash\n\n# Set deployment name and namespace\nPROBE_TYPE=\"\
    ${1:-readinessProbe}\"  # Default to livenessProbe, can be set to readinessProbe\n\
    \n# Function to extract data using jq\nextract_data() {\n    echo \"$1\" | jq\
    \ -r \"$2\" 2>/dev/null  # jq used to extract data in JSON format\n}\n\n# Function\
    \ to extract port from command\nextract_port_from_command() {\n    echo \"$1\"\
    \ | grep -oE ':[0-9]+' | grep -oE '[0-9]+' | head -n 1  # regex used to extract\
    \ ports\n}\n\n# Get deployment manifest in JSON format\nMANIFEST=$(${KUBERNETES_DISTRIBUTION_BINARY}\
    \ get deployment \"$DEPLOYMENT_NAME\" -n \"$NAMESPACE\" --context \"$CONTEXT\"\
    \ -o json)  # Fetching deployment details using kubernetes distribution binary\
    \ \nif [ $? -ne 0 ]; then  # Check if error occurred while fetching deployment\
    \ details\n    echo \"Error fetching deployment details: $MANIFEST\"\n    exit\
    \ 1\nfi\n\n# Get number of containers\nNUM_CONTAINERS=$(extract_data \"$MANIFEST\"\
    \ '.spec.template.spec.containers | length')  # Extracting number of containers\n\
    if [ -z \"$NUM_CONTAINERS\" ]; then  # Check if no containers found\n    echo\
    \ \"No containers found in deployment.\"\n    exit 1\nfi\n\nnext_steps=()  # Initialize\
    \ empty array for next steps\n\n# Loop through containers and validate probes\n\
    for ((i=0; i<NUM_CONTAINERS; i++)); do\n    PROBE=$(extract_data \"$MANIFEST\"\
    \ \".spec.template.spec.containers[$i].${PROBE_TYPE}\")  # Extracting type of\
    \ probe for each container\n    CONTAINER_NAME=$(extract_data \"$MANIFEST\" \"\
    .spec.template.spec.containers[$i].name\")  # Extracting container name\n    echo\
    \ \"-------- START Validation - Container Name: $CONTAINER_NAME Probe Type: $PROBE_TYPE\
    \ -------\"\n    echo \"Container: \\`$CONTAINER_NAME\\`\"\n    echo \"$PROBE_TYPE:\
    \ $PROBE\"\n\n    # List container ports\n    CONTAINER_PORTS=$(extract_data \"\
    $MANIFEST\" \".spec.template.spec.containers[$i].ports[].containerPort\")  # Extracting\
    \ exposed ports for the container\n    if [ -n \"$CONTAINER_PORTS\" ]; then\n\
    \        echo \"Exposed Ports: $CONTAINER_PORTS\"\n    else:\n        echo \"\
    No ports exposed.\"\n    fi\n\n    if [ -z \"$PROBE\" ]; then  # Check if probe\
    \ not found for container\n        echo \"Container \\`$CONTAINER_NAME\\`: ${PROBE_TYPE}\
    \ not found.\"\n        continue\n    fi\n\n    # Validate that the port in the\
    \ probe is defined in the container's ports\n    if echo \"$PROBE\" | jq -e '.httpGet,\
    \ .tcpSocket' >/dev/null; then  # Check if HTTP GET or TCP Socket present\n  \
    \      PROBE_PORT=$(extract_data \"$PROBE\" '.httpGet.port // .tcpSocket.port')\
    \  # Extracting port for probe\n        CONTAINER_PORTS=$(extract_data \"$MANIFEST\"\
    \ \".spec.template.spec.containers[$i].ports[].containerPort\")  # Extracting\
    \ container ports\n\n        if [[ ! \" $CONTAINER_PORTS \" == *\"$PROBE_PORT\"\
    * ]]; then  # Check if probe port exists in container ports\n            echo\
    \ \"Container \\`$CONTAINER_NAME\\`: Port $PROBE_PORT used in $PROBE_TYPE is not\
    \ exposed by the container.\"\n            next_steps+=(\"Update $PROBE_TYPE For\
    \ \\`${DEPLOYMENT_NAME}\\` to use one of the following ports: $CONTAINER_PORTS\"\
    )\n        else:\n            echo \"Container \\`$CONTAINER_NAME\\`: ${PROBE_TYPE}\
    \ port $PROBE_PORT is valid.\"\n        fi\n    fi\n\n    # Check if exec permissions\
    \ are available (for exec type probes)\n    if echo \"$PROBE\" | jq -e '.exec'\
    \ >/dev/null; then  # Check if exec exists\n        IFS=$'\\n' read -r -d '' -a\
    \ EXEC_COMMAND_ARRAY < <(echo \"$PROBE\" | jq -r '.exec.command[]' && printf '\\\
    0')  # Extracting exec command\n        PORT_IN_COMMAND=$(extract_port_from_command\
    \ \"${EXEC_COMMAND_ARRAY[*]}\")  # Extracting port from exec command\n\n     \
    \   # Check if we see the port in the exec command, and if so, if it's defined\
    \ in the manifest\n        if [ -n \"$PORT_IN_COMMAND\" ]; then  # Check if port\
    \ exists in exec command\n            CONTAINER_PORTS=$(extract_data \"$MANIFEST\"\
    \ \".spec.template.spec.containers[$i].ports[].containerPort\")  # Extracting\
    \ container ports\n            if [[ ! \" $CONTAINER_PORTS \" == *\"$PORT_IN_COMMAND\"\
    * ]]; then  # Check if port exists in container ports\n                echo \"\
    Container \\`$CONTAINER_NAME\\`: Port $PORT_IN_COMMAND used in ${PROBE_TYPE} exec\
    \ command is not exposed by the container. The following ports are exposed: $CONTAINER_PORTS\"\
    \n                next_steps+=(\"Get Deployment Workload Details For \\`$DEPLOYMENT_NAME\\\
    `\")\n                next_steps+=(\"Remediate Readiness and Liveness Probes for\
    \ Deployments in Namespace \\`${NAMESPACE}\\`\")\n            else:\n        \
    \        echo \"Container \\`$CONTAINER_NAME\\`: Port $PORT_IN_COMMAND in ${PROBE_TYPE}\
    \ exec command is valid.\"\n            fi\n        fi\n\n        # Check exec\
    \ permission and execute command\n        if ${KUBERNETES_DISTRIBUTION_BINARY}\
    \ auth can-i create pods/exec -n \"$NAMESPACE\" >/dev/null 2>&1; then  # Check\
    \ exec permissions\n            # Execute command\n            # ...\n       \
    \     # ... (more code to execute command and test ports)\n\n        else\n  \
    \          echo \"Exec permission is not available.\"\n        fi\n    fi\n  \
    \  echo \"------- END Validation - Container Name: $CONTAINER_NAME Probe Type:\
    \ $PROBE_TYPE -------\"\ndone\n\n# Display all unique recommendations that can\
    \ be shown as Next Steps\nif [[ ${#next_steps[@]} -ne 0 ]]; then  # Check if there\
    \ are any next steps\n    printf \"\\nRecommended Next Steps: \\n\"\n    printf\
    \ \"%s\\n\" \"${next_steps[@]}\" | sort -u  # Print unique next steps\nfi\n"
  name: check_readiness_probe_configuration_for_deployment_deployment_name
  when_is_it_useful: '1. Deploying a new application or service to a Kubernetes cluster
    and wanting to ensure that the probes are correctly configured to monitor the
    health and readiness of the application.


    2. Troubleshooting ongoing issues with applications or services experiencing CrashLoopBackoff
    events within a Kubernetes cluster, and needing to verify if the probe configurations
    are contributing to the problem.


    3. Performing routine maintenance or updates on existing deployments in a Kubernetes
    cluster and wanting to ensure that all probe configurations are set up correctly
    before making any changes.


    4. Investigating performance issues within a Kubernetes cluster and wanting to
    validate the probe configurations for potential improvements in monitoring and
    managing the health of applications.


    5. Onboarding new team members or colleagues to work on managing Kubernetes deployments
    and wanting to provide a tool for them to easily validate and understand the probe
    configurations in deployment manifests.'
- command: 'kubectl get events --context ${CONTEXT} -n ${NAMESPACE} -o json | jq ''(now
    - (60*60)) as $time_limit | [ .items[] | select(.type == "Warning" and (.involvedObject.kind
    == "Deployment" or .involvedObject.kind == "ReplicaSet" or .involvedObject.kind
    == "Pod") and (.involvedObject.name | tostring | contains("${DEPLOYMENT_NAME}"))
    and (.lastTimestamp | fromdateiso8601) >= $time_limit) | {kind: .involvedObject.kind,
    name: .involvedObject.name, reason: .reason, message: .message, firstTimestamp:
    .firstTimestamp, lastTimestamp: .lastTimestamp} ] | group_by([.kind, .name]) |
    map({kind: .[0].kind, name: .[0].name, count: length, reasons: map(.reason) |
    unique, messages: map(.message) | unique, firstTimestamp: map(.firstTimestamp
    | fromdateiso8601) | sort | .[0] | todateiso8601, lastTimestamp: map(.lastTimestamp
    | fromdateiso8601) | sort | reverse | .[0] | todateiso8601})'''
  doc_links: '

    - [Kubectl Cheat Sheet](https://kubernetes.io/docs/reference/kubectl/cheatsheet/){:target="_blank"}

    - [Kubectl Get Command Documentation](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#get){:target="_blank"}

    - [Kubectl JSONPath Guide](https://kubernetes.io/docs/reference/kubectl/jsonpath/){:target="_blank"}'
  explanation: This command is using kubectl to get events from a specific context
    and namespace in JSON format, then filtering the results to show only warnings
    related to Deployments, ReplicaSets, or Pods with a specific name within the last
    hour. The output is grouped by kind and name, showing the count, unique reasons,
    unique messages, first and last timestamps of the warning events.
  multi_line_details: "\n# Get events from a Kubernetes cluster in a specific context\
    \ and namespace in JSON format\nkubectl get events --context ${CONTEXT} -n ${NAMESPACE}\
    \ -o json | \\\n\n# Use jq to filter and format the data\njq '\n# Define a time\
    \ limit based on 1 hour ago\n(now - (60*60)) as $time_limit |\n\n# Filter and\
    \ map items based on certain conditions\n[ .items[] | \n\n# Select only Warning\
    \ events related to Deployment, ReplicaSet, or Pod\nselect(.type == \"Warning\"\
    \ and \n       (.involvedObject.kind == \"Deployment\" or\n        .involvedObject.kind\
    \ == \"ReplicaSet\" or\n        .involvedObject.kind == \"Pod\") and\n\n# Make\
    \ sure the name contains the given deployment name\n        (.involvedObject.name\
    \ | tostring | contains(\"${DEPLOYMENT_NAME}\")) and\n\n# Check if lastTimestamp\
    \ is more recent than the time limit\n        (.lastTimestamp | fromdateiso8601)\
    \ >= $time_limit) | \n\n# Create a new object with selected properties\n{kind:\
    \ .involvedObject.kind, \n name: .involvedObject.name, \n reason: .reason, \n\
    \ message: .message, \n firstTimestamp: .firstTimestamp, \n lastTimestamp: .lastTimestamp}\
    \ ] |\n\n# Group the objects by kind and name\ngroup_by([.kind, .name]) | \n\n\
    # Map the grouped objects into a desired format\nmap({kind: .[0].kind, \n    \
    \ name: .[0].name, \n     count: length, \n     reasons: map(.reason) | unique,\
    \ \n     messages: map(.message) | unique, \n     firstTimestamp: map(.firstTimestamp\
    \ | fromdateiso8601) | sort | .[0] | todateiso8601, \n     lastTimestamp: map(.lastTimestamp\
    \ | fromdateiso8601) | sort | reverse | .[0] | todateiso8601})'\n"
  name: inspect_deployment_warning_events_for_deployment_name
  when_is_it_useful: '1. Monitoring and troubleshooting Kubernetes applications: A
    DevOps or Site Reliability Engineer might use this command to quickly identify
    and address warning events related to Deployments, ReplicaSets, or Pods within
    a specific timeframe, in order to ensure the stability and performance of the
    application.


    2. Investigating performance issues: In the event of performance degradation or
    intermittent errors within a Kubernetes cluster, a DevOps or Site Reliability
    Engineer may use this command to pinpoint warning events related to specific resources
    and assess the impact on overall performance.


    3. Debugging CrashLoopBackoff events: When dealing with recurring CrashLoopBackoff
    events in Kubernetes, a DevOps or Site Reliability Engineer could utilize this
    command to gather and analyze warning events associated with Pods, identifying
    potential issues that are causing the continuous restarts.


    4. Incident response and resolution: During incident response activities, such
    as service outages or disruptions, a DevOps or Site Reliability Engineer may employ
    this command to swiftly isolate warning events impacting critical resources and
    take corrective actions to mitigate the impact on the system.


    5. Proactive maintenance and optimization: As part of routine maintenance and
    optimization efforts, a DevOps or Site Reliability Engineer might use this command
    to regularly review warning events within a specified timeframe, identifying patterns
    or trends that require further investigation and remediation to ensure the overall
    health of the Kubernetes environment.'
- command: 'kubectl get events --context ${CONTEXT} -n ${NAMESPACE} -o json | jq ''(now
    - (60*60)) as $time_limit | [ .items[] | select(.type == "Warning" and (.involvedObject.kind
    == "Deployment" or .involvedObject.kind == "ReplicaSet" or .involvedObject.kind
    == "Pod") and (.involvedObject.name | tostring | contains("${DEPLOYMENT_NAME}"))
    and (.lastTimestamp | fromdateiso8601) >= $time_limit) | {kind: .involvedObject.kind,
    name: .involvedObject.name, reason: .reason, message: .message, firstTimestamp:
    .firstTimestamp, lastTimestamp: .lastTimestamp} ] | group_by([.kind, .name]) |
    map({kind: .[0].kind, name: .[0].name, count: length, reasons: map(.reason) |
    unique, messages: map(.message) | unique, firstTimestamp: map(.firstTimestamp
    | fromdateiso8601) | sort | .[0] | todateiso8601, lastTimestamp: map(.lastTimestamp
    | fromdateiso8601) | sort | reverse | .[0] | todateiso8601})'''
  doc_links: '

    - [Kubectl Cheat Sheet](https://kubernetes.io/docs/reference/kubectl/cheatsheet/){:target="_blank"}

    - [Kubectl Get Command Documentation](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#get){:target="_blank"}

    - [Kubectl JSONPath Guide](https://kubernetes.io/docs/reference/kubectl/jsonpath/){:target="_blank"}'
  explanation: This command is using kubectl to get events from a specific context
    and namespace in JSON format, then filtering the results to show only warnings
    related to Deployments, ReplicaSets, or Pods with a specific name within the last
    hour. The output is grouped by kind and name, showing the count, unique reasons,
    unique messages, first and last timestamps of the warning events.
  multi_line_details: "\n# Get events from a Kubernetes cluster in a specific context\
    \ and namespace in JSON format\nkubectl get events --context ${CONTEXT} -n ${NAMESPACE}\
    \ -o json | \\\n\n# Use jq to filter and format the data\njq '\n# Define a time\
    \ limit based on 1 hour ago\n(now - (60*60)) as $time_limit |\n\n# Filter and\
    \ map items based on certain conditions\n[ .items[] | \n\n# Select only Warning\
    \ events related to Deployment, ReplicaSet, or Pod\nselect(.type == \"Warning\"\
    \ and \n       (.involvedObject.kind == \"Deployment\" or\n        .involvedObject.kind\
    \ == \"ReplicaSet\" or\n        .involvedObject.kind == \"Pod\") and\n\n# Make\
    \ sure the name contains the given deployment name\n        (.involvedObject.name\
    \ | tostring | contains(\"${DEPLOYMENT_NAME}\")) and\n\n# Check if lastTimestamp\
    \ is more recent than the time limit\n        (.lastTimestamp | fromdateiso8601)\
    \ >= $time_limit) | \n\n# Create a new object with selected properties\n{kind:\
    \ .involvedObject.kind, \n name: .involvedObject.name, \n reason: .reason, \n\
    \ message: .message, \n firstTimestamp: .firstTimestamp, \n lastTimestamp: .lastTimestamp}\
    \ ] |\n\n# Group the objects by kind and name\ngroup_by([.kind, .name]) | \n\n\
    # Map the grouped objects into a desired format\nmap({kind: .[0].kind, \n    \
    \ name: .[0].name, \n     count: length, \n     reasons: map(.reason) | unique,\
    \ \n     messages: map(.message) | unique, \n     firstTimestamp: map(.firstTimestamp\
    \ | fromdateiso8601) | sort | .[0] | todateiso8601, \n     lastTimestamp: map(.lastTimestamp\
    \ | fromdateiso8601) | sort | reverse | .[0] | todateiso8601})'\n"
  name: inspect_deployment_warning_events_for_deployment_name
  when_is_it_useful: '1. Monitoring and troubleshooting Kubernetes applications: A
    DevOps or Site Reliability Engineer might use this command to quickly identify
    and address warning events related to Deployments, ReplicaSets, or Pods within
    a specific timeframe, in order to ensure the stability and performance of the
    application.


    2. Investigating performance issues: In the event of performance degradation or
    intermittent errors within a Kubernetes cluster, a DevOps or Site Reliability
    Engineer may use this command to pinpoint warning events related to specific resources
    and assess the impact on overall performance.


    3. Debugging CrashLoopBackoff events: When dealing with recurring CrashLoopBackoff
    events in Kubernetes, a DevOps or Site Reliability Engineer could utilize this
    command to gather and analyze warning events associated with Pods, identifying
    potential issues that are causing the continuous restarts.


    4. Incident response and resolution: During incident response activities, such
    as service outages or disruptions, a DevOps or Site Reliability Engineer may employ
    this command to swiftly isolate warning events impacting critical resources and
    take corrective actions to mitigate the impact on the system.


    5. Proactive maintenance and optimization: As part of routine maintenance and
    optimization efforts, a DevOps or Site Reliability Engineer might use this command
    to regularly review warning events within a specified timeframe, identifying patterns
    or trends that require further investigation and remediation to ensure the overall
    health of the Kubernetes environment.'
- command: kubectl get deployment/${DEPLOYMENT_NAME} --context ${CONTEXT} -n ${NAMESPACE}
    -o yaml
  doc_links: '

    '
  explanation: This command is used to retrieve the YAML configuration for a specific
    deployment in a Kubernetes cluster, specified by the deployment name, context,
    and namespace. It's a way to view the detailed configuration settings for that
    deployment.
  multi_line_details: "\n# The following command is used to retrieve the configuration\
    \ details of a specific deployment in a YAML format\n\n# Use kubectl to get the\
    \ deployment with the specified name\nkubectl get deployment/${DEPLOYMENT_NAME}\
    \ \n\n# Specify the context for the cluster where the deployment resides \n--context\
    \ ${CONTEXT}\n\n# Specify the namespace where the deployment is located\n-n ${NAMESPACE}\
    \ \n\n# Output the details in YAML format for easier reading and manipulation\n\
    -o yaml\n"
  name: get_deployment_workload_details_for_deployment_name_and_add_to_report
  when_is_it_useful: '1. Troubleshooting Kubernetes CrashLoopBackoff events: When
    a deployment is continuously crashing and restarting, a DevOps or SRE might use
    this command to retrieve the YAML configuration in order to review the settings
    and find any misconfigurations that could be causing the issue.


    2. Investigating performance issues: If there are performance issues with a specific
    deployment, a DevOps or SRE might use this command to view the detailed configuration
    and identify any potential bottlenecks or inefficiencies.


    3. Auditing and documentation: In order to keep track of the configurations for
    different deployments, a DevOps or SRE might use this command to retrieve the
    YAML configuration and document it for future reference or auditing purposes.


    4. Comparing configurations: When comparing the settings of different deployments
    or versions of a deployment, a DevOps or SRE might use this command to retrieve
    the YAML configuration and compare them side by side.


    5. Making changes to the deployment: Before making any changes to the deployment
    configuration, a DevOps or SRE might use this command to retrieve the current
    configuration as a reference point for the updates.'
- command: kubectl get deployment/${DEPLOYMENT_NAME} --context ${CONTEXT} -n ${NAMESPACE}
    -o yaml
  doc_links: '

    '
  explanation: This command is used to retrieve the YAML configuration for a specific
    deployment in a Kubernetes cluster, specified by the deployment name, context,
    and namespace. It's a way to view the detailed configuration settings for that
    deployment.
  multi_line_details: "\n# The following command is used to retrieve the configuration\
    \ details of a specific deployment in a YAML format\n\n# Use kubectl to get the\
    \ deployment with the specified name\nkubectl get deployment/${DEPLOYMENT_NAME}\
    \ \n\n# Specify the context for the cluster where the deployment resides \n--context\
    \ ${CONTEXT}\n\n# Specify the namespace where the deployment is located\n-n ${NAMESPACE}\
    \ \n\n# Output the details in YAML format for easier reading and manipulation\n\
    -o yaml\n"
  name: get_deployment_workload_details_for_deployment_name_and_add_to_report
  when_is_it_useful: '1. Troubleshooting Kubernetes CrashLoopBackoff events: When
    a deployment is continuously crashing and restarting, a DevOps or SRE might use
    this command to retrieve the YAML configuration in order to review the settings
    and find any misconfigurations that could be causing the issue.


    2. Investigating performance issues: If there are performance issues with a specific
    deployment, a DevOps or SRE might use this command to view the detailed configuration
    and identify any potential bottlenecks or inefficiencies.


    3. Auditing and documentation: In order to keep track of the configurations for
    different deployments, a DevOps or SRE might use this command to retrieve the
    YAML configuration and document it for future reference or auditing purposes.


    4. Comparing configurations: When comparing the settings of different deployments
    or versions of a deployment, a DevOps or SRE might use this command to retrieve
    the YAML configuration and compare them side by side.


    5. Making changes to the deployment: Before making any changes to the deployment
    configuration, a DevOps or SRE might use this command to retrieve the current
    configuration as a reference point for the updates.'
- command: 'kubectl get deployment/${DEPLOYMENT_NAME} --context ${CONTEXT} -n ${NAMESPACE}
    -o json | jq ''.status | {desired_replicas: .replicas, ready_replicas: (.readyReplicas
    // 0), missing_replicas: ((.replicas // 0) - (.readyReplicas // 0)), unavailable_replicas:
    (.unavailableReplicas // 0), available_condition: (if any(.conditions[]; .type
    == "Available") then (.conditions[] | select(.type == "Available")) else "Condition
    not available" end), progressing_condition: (if any(.conditions[]; .type == "Progressing")
    then (.conditions[] | select(.type == "Progressing")) else "Condition not available"
    end)}'''
  doc_links: '

    '
  explanation: This command retrieves information about a specific deployment from
    the Kubernetes cluster, including the number of desired, ready, missing, and unavailable
    replicas, as well as the available and progressing conditions. It uses jq to filter
    and format the information in JSON output.
  multi_line_details: "\n# Set variables for the deployment name, context, and namespace\n\
    DEPLOYMENT_NAME=my-deployment\nCONTEXT=my-context\nNAMESPACE=my-namespace\n\n\
    # Retrieve details about the specified deployment in JSON format, use 'jq' to\
    \ parse the information\nkubectl get deployment/${DEPLOYMENT_NAME} --context ${CONTEXT}\
    \ -n ${NAMESPACE} -o json | \\\n    jq '.status | {\n        desired_replicas:\
    \ .replicas,\n        ready_replicas: (.readyReplicas // 0),\n        missing_replicas:\
    \ ((.replicas // 0) - (.readyReplicas // 0)),\n        unavailable_replicas: (.unavailableReplicas\
    \ // 0),\n        available_condition: (if any(.conditions[]; .type == \"Available\"\
    ) then \n                                (.conditions[] | select(.type == \"Available\"\
    )) \n                              else \"Condition not available\" end),\n  \
    \      progressing_condition: (if any(.conditions[]; .type == \"Progressing\"\
    ) then \n                                  (.conditions[] | select(.type == \"\
    Progressing\")) \n                                else \"Condition not available\"\
    \ end)\n    }'\n"
  name: inspect_deployment_replicas_for_deployment_name
  when_is_it_useful: '1. Monitoring the health and status of a specific deployment
    in a Kubernetes cluster to ensure that it is functioning as expected.

    2. Debugging issues related to the availability and readiness of replicas within
    a deployment, such as pods continuously restarting or not being able to start.

    3. Investigating and troubleshooting CrashLoopBackoff events that may be occurring
    within a deployment.

    4. Analyzing and diagnosing problems with progressing conditions for a deployment,
    such as delays or failures in updating and rolling out new versions of an application.

    5. Gathering detailed information about the current state of a deployment in order
    to make informed decisions and take appropriate actions, such as scaling or modifying
    its configuration.'
- command: 'kubectl get deployment/${DEPLOYMENT_NAME} --context ${CONTEXT} -n ${NAMESPACE}
    -o json | jq ''.status | {desired_replicas: .replicas, ready_replicas: (.readyReplicas
    // 0), missing_replicas: ((.replicas // 0) - (.readyReplicas // 0)), unavailable_replicas:
    (.unavailableReplicas // 0), available_condition: (if any(.conditions[]; .type
    == "Available") then (.conditions[] | select(.type == "Available")) else "Condition
    not available" end), progressing_condition: (if any(.conditions[]; .type == "Progressing")
    then (.conditions[] | select(.type == "Progressing")) else "Condition not available"
    end)}'''
  doc_links: '

    '
  explanation: This command retrieves information about a specific deployment from
    the Kubernetes cluster, including the number of desired, ready, missing, and unavailable
    replicas, as well as the available and progressing conditions. It uses jq to filter
    and format the information in JSON output.
  multi_line_details: "\n# Set variables for the deployment name, context, and namespace\n\
    DEPLOYMENT_NAME=my-deployment\nCONTEXT=my-context\nNAMESPACE=my-namespace\n\n\
    # Retrieve details about the specified deployment in JSON format, use 'jq' to\
    \ parse the information\nkubectl get deployment/${DEPLOYMENT_NAME} --context ${CONTEXT}\
    \ -n ${NAMESPACE} -o json | \\\n    jq '.status | {\n        desired_replicas:\
    \ .replicas,\n        ready_replicas: (.readyReplicas // 0),\n        missing_replicas:\
    \ ((.replicas // 0) - (.readyReplicas // 0)),\n        unavailable_replicas: (.unavailableReplicas\
    \ // 0),\n        available_condition: (if any(.conditions[]; .type == \"Available\"\
    ) then \n                                (.conditions[] | select(.type == \"Available\"\
    )) \n                              else \"Condition not available\" end),\n  \
    \      progressing_condition: (if any(.conditions[]; .type == \"Progressing\"\
    ) then \n                                  (.conditions[] | select(.type == \"\
    Progressing\")) \n                                else \"Condition not available\"\
    \ end)\n    }'\n"
  name: inspect_deployment_replicas_for_deployment_name
  when_is_it_useful: '1. Monitoring the health and status of a specific deployment
    in a Kubernetes cluster to ensure that it is functioning as expected.

    2. Debugging issues related to the availability and readiness of replicas within
    a deployment, such as pods continuously restarting or not being able to start.

    3. Investigating and troubleshooting CrashLoopBackoff events that may be occurring
    within a deployment.

    4. Analyzing and diagnosing problems with progressing conditions for a deployment,
    such as delays or failures in updating and rolling out new versions of an application.

    5. Gathering detailed information about the current state of a deployment in order
    to make informed decisions and take appropriate actions, such as scaling or modifying
    its configuration.'
- command: bash 'event_anomalies.sh'
  doc_links: '

    - [Kubernetes Events API Reference](https://kubernetes.io/docs/reference/using-api/api-concepts/#kubernetes-events){:target="_blank"}

    - [jq Manual](https://stedolan.github.io/jq/manual/){:target="_blank"}

    - [Kubernetes Deployment Documentation](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/){:target="_blank"}

    - [Kubernetes ReplicaSet Documentation](https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/){:target="_blank"}

    - [Kubernetes Pods Documentation](https://kubernetes.io/docs/concepts/workloads/pods/){:target="_blank"}'
  explanation: This script is using a bash shell to retrieve Kubernetes events in
    JSON format, processing and filtering the data using jq, and then outputting the
    processed events. It's likely used for monitoring and analyzing events related
    to Kubernetes deployments, replica sets, and pods.
  multi_line_details: "\n#!/bin/bash\n\n# Assuming environment variables are already\
    \ exported and available\n\n# Command to get Kubernetes events in JSON format\n\
    EVENTS_JSON=$(${KUBERNETES_DISTRIBUTION_BINARY} get events --context ${CONTEXT}\
    \ -n ${NAMESPACE} -o json)\n\n# Use jq to process the JSON, skipping events without\
    \ valid timestamps\nPROCESSED_EVENTS=$(echo \"${EVENTS_JSON}\" | jq --arg DEPLOYMENT_NAME\
    \ \"${DEPLOYMENT_NAME}\" '\n  [ .items[]\n    | select(\n        .type != \"Warning\"\
    \                                    # Filtering out warning events\n        and\
    \ (.involvedObject.kind | test(\"Deployment|ReplicaSet|Pod\"))   # Selecting events\
    \ related to Deployment, ReplicaSet, or Pod\n        and (.involvedObject.name\
    \ | contains($DEPLOYMENT_NAME))         # Selecting events with specific deployment\
    \ name\n        and (.firstTimestamp | fromdateiso8601? // empty) and (.lastTimestamp\
    \ | fromdateiso8601? // empty)      # Checking for valid timestamps\n      )\n\
    \    | {\n        kind: .involvedObject.kind,                    # Extracting\
    \ relevant information from each event\n        count: .count,\n        name:\
    \ .involvedObject.name,\n        reason: .reason,\n        message: .message,\n\
    \        firstTimestamp: .firstTimestamp,\n        lastTimestamp: .lastTimestamp,\n\
    \        duration: (\n          if (((.lastTimestamp | fromdateiso8601) - (.firstTimestamp\
    \ | fromdateiso8601)) == 0)     # Calculating duration of the event\n        \
    \  then 1\n          else (((.lastTimestamp | fromdateiso8601) - (.firstTimestamp\
    \ | fromdateiso8601)) / 60)\n          end\n        )\n      }\n  ]\n  | group_by([.kind,\
    \ .name])                      # Grouping events by kind and name\n  | map({\n\
    \      kind: .[0].kind,                             # Processing grouped events\
    \ to calculate total count, reasons, messages, etc.\n      name: .[0].name,\n\
    \      count: (map(.count) | add),\n      reasons: (map(.reason) | unique),\n\
    \      messages: (map(.message) | unique),\n      average_events_per_minute: (\n\
    \        if .[0].duration == 1                        # Calculating average events\
    \ per minute\n        then 1\n        else ((map(.count) | add) / .[0].duration)\n\
    \        end\n      ),\n      firstTimestamp: (map(.firstTimestamp | fromdateiso8601)\
    \ | sort | .[0] | todateiso8601),  # Finding first and last timestamp of events\n\
    \      lastTimestamp: (map(.lastTimestamp | fromdateiso8601) | sort | reverse\
    \ | .[0] | todateiso8601)\n    })\n')\n\necho \"${PROCESSED_EVENTS}\"\n"
  name: check_deployment_event_anomalies_for_deployment_name
  when_is_it_useful: '1. Monitoring Kubernetes deployments for any CrashLoopBackoff
    events, which could indicate a problem with the application or its environment.

    2. Analyzing the events to identify any performance issues or unusual behavior
    within the Kubernetes cluster.

    3. Troubleshooting issues with pods or replica sets that are not starting or are
    failing repeatedly.

    4. Investigating any unusual or unexpected events occurring within the Kubernetes
    environment, such as sudden spike in errors or resource usage.

    5. Identifying and analyzing events related to pod evictions, which may impact
    application availability and reliability.'
- command: bash 'check_replicaset.sh' | tee "${SCRIPT_TMP_DIR}/rs_analysis"
  doc_links: '

    - [ReplicaSet in Kubernetes](https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/){:target="_blank"}

    - [Kubernetes deployments](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/){:target="_blank"}

    - [JSON data in Kubernetes](https://kubernetes.io/docs/reference/kubectl/jsonpath/){:target="_blank"}'
  explanation: This script is designed to manage ReplicaSets in Kubernetes deployments
    by checking for multiple ReplicaSets, verifying the active latest ReplicaSet,
    and providing actionable insights for any inactive or conflicting ReplicaSets
    during normal operations and rolling updates. It uses a series of checks and operations
    involving JSON data obtained from the Kubernetes cluster.
  multi_line_details: "\n#!/bin/bash\n\n# Kubernetes Deployment ReplicaSet Management\
    \ Script\n# This script checks Kubernetes deployments to ensure they are running\
    \ the latest ReplicaSet. It is designed to manage\n# ReplicaSets during normal\
    \ operations and rolling updates, checking for multiple ReplicaSets, verifying\
    \ the active latest ReplicaSet, and providing actionable insights for any inactive\
    \ or conflicting ReplicaSets.\n\n# Function to check for rolling update status\n\
    check_rolling_update_status() {\n    # Extract conditions and replica counts\n\
    \    local progressingCondition=$(echo \"$DEPLOYMENT_JSON\" | jq '.status.conditions[]\
    \ | select(.type==\"Progressing\")')\n    local availableCondition=$(echo \"$DEPLOYMENT_JSON\"\
    \ | jq '.status.conditions[] | select(.type==\"Available\").status')\n    local\
    \ replicas=$(echo \"$DEPLOYMENT_JSON\" | jq '.status.replicas // 0')\n    local\
    \ updatedReplicas=$(echo \"$DEPLOYMENT_JSON\" | jq '.status.updatedReplicas //\
    \ 0')\n    local availableReplicas=$(echo \"$DEPLOYMENT_JSON\" | jq '.status.availableReplicas\
    \ // 0')\n    local readyReplicas=$(echo \"$DEPLOYMENT_JSON\" | jq '.status.readyReplicas\
    \ // 0')\n\n    # Interpret 'Progressing' condition more accurately\n    local\
    \ progressingStatus=$(echo \"$progressingCondition\" | jq -r '.status')\n    local\
    \ progressingReason=$(echo \"$progressingCondition\" | jq -r '.reason')\n    local\
    \ lastUpdateTime=$(echo \"$progressingCondition\" | jq -r '.lastUpdateTime')\n\
    \n    # Current time in UTC for comparison (assuming 'date' command is available\
    \ and system timezone is correctly set)\n    local currentTime=$(date -u +\"%Y-%m-%dT%H:%M:%SZ\"\
    )\n\n    # Compare replica counts for a more accurate ongoing rollout check\n\
    \    if [[ \"$progressingStatus\" == \"True\" && \"$progressingReason\" == \"\
    NewReplicaSetAvailable\" && \"$updatedReplicas\" == \"$replicas\" && \"$availableReplicas\"\
    \ == \"$updatedReplicas\" && \"$readyReplicas\" == \"$updatedReplicas\" ]]; then\n\
    \        # Check how recent the last update was to consider a buffer for stabilization\n\
    \        if [[ $(date -d \"$lastUpdateTime\" +%s) -lt $(date -d \"$currentTime\"\
    \ +%s --date='-2 minutes') ]]; then\n            echo \"Deployment $DEPLOYMENT_NAME\
    \ is stable. No active rollout detected.\"\n            ROLLING_UPDATE_STATUS=1\
    \ # Indicates no update is in progress\n        else\n            echo \"Deployment\
    \ $DEPLOYMENT_NAME has recently updated and may still be stabilizing.\"\n    \
    \        ROLLING_UPDATE_STATUS=0 # Indicates recent update, considering stabilization\n\
    \        fi\n    elif [[ \"$updatedReplicas\" -lt \"$replicas\" ]] || [[ \"$availableReplicas\"\
    \ -lt \"$updatedReplicas\" ]] || [[ \"$readyReplicas\" -lt \"$updatedReplicas\"\
    \ ]]; then\n        echo \"Deployment $DEPLOYMENT_NAME is undergoing a rollout.\"\
    \n        ROLLING_UPDATE_STATUS=0 # Indicates an update is in progress\n    else\n\
    \        echo \"Deployment $DEPLOYMENT_NAME is stable. No active rollout detected.\"\
    \n        ROLLING_UPDATE_STATUS=1 # Indicates no update is in progress\n    fi\n\
    }\n\nverify_pods_association_with_latest_rs() {\n    # Fetch all pods associated\
    \ with the deployment\n    PODS_JSON=$(${KUBERNETES_DISTRIBUTION_BINARY} get pods\
    \ -n $NAMESPACE --context $CONTEXT --selector=app=$DEPLOYMENT_NAME --context $CONTEXT\
    \ -o json)\n    PODS_COUNT=$(echo \"$PODS_JSON\" | jq '.items | length')\n   \
    \ OUTDATED_PODS_COUNT=0\n\n    for ((i=0; i<PODS_COUNT; i++)); do\n        POD_RS=$(echo\
    \ \"$PODS_JSON\" | jq -r \".items[$i].metadata.ownerReferences[] | select(.kind\
    \ == \\\"ReplicaSet\\\") | .name\")\n        if [[ \"$POD_RS\" != \"$LATEST_RS\"\
    \ ]]; then\n            OUTDATED_PODS_COUNT=$((OUTDATED_PODS_COUNT + 1))\n   \
    \     fi\n    done\n\n    if [[ \"$OUTDATED_PODS_COUNT\" -eq 0 ]]; then\n    \
    \    echo \"All pods are correctly associated with the latest ReplicaSet.\"\n\
    \    else\n        echo \"Warning: $OUTDATED_PODS_COUNT pod(s) are not associated\
    \ with the latest ReplicaSet.\"\n        issue_details=\"{\\\"severity\\\":\\\"\
    2\\\",\\\"title\\\":\\\"$OUTDATED_PODS_COUNT pod(s) are not running the latest\
    \ version of Deployment \\`$DEPLOYMENT_NAME\\` in namespace \\`${NAMESPACE}\\\
    `\\\",\\\"next_steps\\\":\\\"Clean up stale ReplicaSet \\`$RS\\` for Deployment\
    \ \\`$DEPLOYMENT_NAME\\` in namespace \\`${NAMESPACE}\\` \\\",\\\"details\\\"\
    :\\\"$RS_DETAILS\\\"}\"\n    fi\n}\n\n# Get Deployment JSON\nDEPLOYMENT_JSON=$(${KUBERNETES_DISTRIBUTION_BINARY}\
    \ get deployment $DEPLOYMENT_NAME -n $NAMESPACE --context $CONTEXT -o json)\n\n\
    # Get the deployment's latest ReplicaSet\nREPLICASETS_JSON=$(${KUBERNETES_DISTRIBUTION_BINARY}\
    \ get rs -n $NAMESPACE --context $CONTEXT -o json | jq --arg DEPLOYMENT_NAME \"\
    $DEPLOYMENT_NAME\" \\\n    '[.items[] | select(.metadata.ownerReferences[]? |\
    \ select(.kind == \"Deployment\" and .name == $DEPLOYMENT_NAME))]')\n\n# Extract\
    \ the name of the latest ReplicaSet from the filtered JSON\nLATEST_RS=$(echo \"\
    $REPLICASETS_JSON\" | jq -r 'sort_by(.metadata.creationTimestamp) | last(.[]).metadata.name')\n\
    \n# Extract names of all ReplicaSets associated with the Deployment from the filtered\
    \ JSON\nALL_RS=$(echo \"$REPLICASETS_JSON\" | jq -r '.[].metadata.name' | tr '\\\
    n' ' ')\nreadarray -t ALL_RS_NAMES < <(echo \"$REPLICASETS_JSON\" | jq -r '.[].metadata.name')\n\
    \necho \"Latest ReplicaSet: $LATEST_RS\"\necho \"All ReplicaSets for the deployment:\
    \ $ALL_RS\"\n\nROLLING_UPDATE_STATUS=-1 # Default to -1; will be set to 0 or 1\
    \ by check_rolling_update_status\ncheck_rolling_update_status\n\n# Check if there\
    \ are multiple ReplicaSets and if the latest is active\nif [[ $(echo $ALL_RS |\
    \ tr ' ' '\\n' | wc -l) -gt 1 ]]; then\n    echo \"Multiple ReplicaSets detected.\
    \ Verifying...\"\n\n    # Loop through all ReplicaSets\n    for RS in $ALL_RS;\
    \ do\n        # Skip the latest ReplicaSet\n        if [[ \"$RS\" == \"$LATEST_RS\"\
    \ ]]; then\n            continue\n        fi\n\n        # Check the status of\
    \ older ReplicaSets (replicas, availableReplicas, readyReplicas)\n        RS_DETAILS_JSON=$(echo\
    \ \"$REPLICASETS_JSON\" | jq --arg RS \"$RS\" '.[] | select(.metadata.name==$RS)')\n\
    \        REPLICAS=$(echo \"$RS_DETAILS_JSON\" | jq '.status.replicas')\n     \
    \   if [[ \"$REPLICAS\" == \"0\" ]]; then\n            echo \"ReplicaSet $RS for\
    \ Deployment $DEPLOYMENT_NAME is not active. Consider for cleanup...\"\n     \
    \   else\n            if [[ $ROLLING_UPDATE_STATUS -eq 0 ]]; then\n          \
    \      date\n                echo \"Multiple ReplicaSets are active, which is\
    \ expected due to the rolling update process.\"\n                issue_details=\"\
    {\\\"severity\\\":\\\"4\\\",\\\"title\\\":\\\"A rolling update is in progress\
    \ for Deployment \\`$DEPLOYMENT_NAME\\` in namespace \\`${NAMESPACE}\\`\\\",\\\
    \"next_steps\\\":\\\"Wait for Rollout to Complete and Check Again.\\\",\\\"details\\\
    \":\\\"$RS_DETAILS\\\"}\"\n                \n            elif [[ $ROLLING_UPDATE_STATUS\
    \ -eq 1 ]]; then\n                echo \"Multiple ReplicaSets are active and no\
    \ update appears to be in place. Investigation may be required to ensure they\
    \ are not conflicting.\"\n                verify_pods_association_with_latest_rs\n\
    \                issue_details=\"{\\\"severity\\\":\\\"2\\\",\\\"title\\\":\\\"\
    Conflicting versions detected for Deployment \\`$DEPLOYMENT_NAME\\` in namespace\
    \ \\`${NAMESPACE}\\`\\\",\\\"next_steps\\\":\\\"Clean up stale ReplicaSet \\`$RS\\\
    ` for Deployment \\`$DEPLOYMENT_NAME\\` in namespace \\`${NAMESPACE}\\` \\\",\\\
    \"details\\\":\\\"$RS_DETAILS_JSON\\\"}\"\n            else\n                echo\
    \ \"Multiple ReplicaSets are active and no update appears to be in place. Investigation\
    \ may be required to ensure they are not conflicting.\"\n            fi\n    \
    \    fi\n    \n        # Initialize issues as an empty array if not already set\n\
    \        if [ -z \"$issues\" ]; then\n            issues=\"[]\"\n        fi\n\n\
    \        # Concatenate issue detail to the string\n        if [ -n \"$issue_details\"\
    \ ]; then\n            # Remove the closing bracket from issues to prepare for\
    \ adding a new item\n            issues=\"${issues%]}\"\n\n            # If issues\
    \ is not an empty array (more than just \"[\"), add a comma before the new item\n\
    \            if [ \"$issues\" != \"[\" ]; then\n                issues=\"$issues,\"\
    \n            fi\n\n            # Add the new issue detail and close the array\n\
    \            issues=\"$issues $issue_details]\"\n        fi\n    done\nelse\n\
    \    echo \"Only one ReplicaSet is active. Deployment is up to date.\"\nfi\n\n\
    \n# Display all unique recommendations that can be shown as Next Steps\nif [ -n\
    \ \"$issues\" ]; then\n    echo -e \"\\nRecommended Next Steps: \\n\"\n    echo\
    \ \"$issues\"\nfi\n"
  name: check_replicaset_health_for_deployment_deployment_name
  when_is_it_useful: '1. During a routine health check of the Kubernetes cluster,
    the DevOps or Site Reliability Engineer may run this script to ensure that all
    ReplicaSets are functioning properly and there are no conflicts or inactive ReplicaSets
    causing issues.


    2. When deploying a new version of an application using rolling updates in Kubernetes,
    the engineer may use this script to verify the status of ReplicaSets and ensure
    that the new ReplicaSet is active and serving traffic while the old one is being
    phased out.


    3. If users report intermittent issues with a specific service or application
    running on Kubernetes, the engineer may use this script to investigate whether
    any ReplicaSets are experiencing CrashLoopBackoff events or other issues that
    could be impacting the availability of the service.


    4. After a scaling event or maintenance activity on the Kubernetes cluster, the
    engineer may utilize this script to validate that all ReplicaSets have scaled
    up or down as expected and that there are no unexpected conflicts or problems
    with the deployment.


    5. As part of a proactive monitoring and alerting strategy, the engineer may schedule
    regular executions of this script to continuously monitor and ensure the stability
    and proper functioning of ReplicaSets in the Kubernetes environment.'
