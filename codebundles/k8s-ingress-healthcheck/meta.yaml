commands:
- command: 'NAMESPACE="${NAMESPACE}";CONTEXT="${CONTEXT}";ingresses=$(kubectl get
    ingress -n "$NAMESPACE" --context "$CONTEXT" -o jsonpath=''{range .items[*]}{.metadata.name}{"\n"}{end}'');for
    ingress in $ingresses;do echo "Ingress: $ingress";health_status="NA";backend_services=$(kubectl
    get ingress "$ingress" -n "$NAMESPACE" --context "$CONTEXT" -o jsonpath=''{range
    .spec.rules[*].http.paths[*]}{.backend.service.name}{"|"}{.backend.service.port.number}{"\n"}{end}'');while
    IFS=''|'' read -r service port;do echo "Backend Service: $service, Port: $port";target_ports=$(kubectl
    get service "$service" -n "$NAMESPACE" --context "$CONTEXT" -o jsonpath="{.spec.ports[?(@.port==$port)].targetPort}");service_exists=$(kubectl
    get service "$service" -n "$NAMESPACE" --context "$CONTEXT" -ojsonpath=''{.metadata.name}'');if
    [ -z "$service_exists" ];then health_status="Unhealthy";echo "Error: Service $service
    does not exist";echo "Next Step: Check namespace $NAMESPACE for service name $service.";continue;else
    selectors=$(kubectl get svc "$service" -n "$NAMESPACE" --context "$CONTEXT" -o
    jsonpath=''{.spec.selector}'');label_selector="";for key in $(echo $selectors
    | jq -r ''keys[]'');do value=$(echo $selectors | jq -r --arg key "$key" ''.[$key]'');label_selector="\${label_selector}\${key}=\${value},";done;label_selector=\${label_selector::-1};found_owner=0;for
    kind in deployment statefulset daemonset;do matching_owners=$(kubectl get $kind
    -n "$NAMESPACE" --context "$CONTEXT" -l "$label_selector" -o jsonpath=''{.items[*].metadata.name}'');if
    [ -n "$matching_owners" ];then for owner in $matching_owners;do echo "Owner Kind:
    $kind";echo "Owner Name: $owner";found_owner=1;done;fi;done;if [ "$found_owner"
    == 0 ];then echo "Error: No matching deployment, statefulset, or daemonset found
    to match label selector \`"$label_selector"\`";echo "Next Steps:\n- Check namespace
    \`"$NAMESPACE"\` for deployment, statefulset, or daemonset with labels that match
    \`"$label_selector"\`";fi;port_found="No";associated_pods=$(kubectl get pods -n
    "$NAMESPACE" --context "$CONTEXT" -l "$label_selector" -o jsonpath=''{.items[*].metadata.name}'');for
    pod in $associated_pods;do container_ports=$(kubectl get pod "$pod" -n "$NAMESPACE"
    --context "$CONTEXT" -o jsonpath=''{.spec.containers[*].ports[*].containerPort}'');for
    target_port in $target_ports;do if echo "$container_ports" | grep -wq "$target_port";then
    port_found="Yes";break;fi;done;done;if [ "$port_found" = "No" ];then health_status="Unhealthy";echo
    "Warning: targetPort $target_ports of service $service is not found as a containerPort
    in associated pods";else health_status="Healthy";fi;endpoint_pods=$(kubectl get
    endpoints "$service" -n "$NAMESPACE" --context "$CONTEXT" -ojsonpath=''{range
    .subsets[*].addresses[*]}- Pod Name: {.targetRef.name}\n Pod IP: {.ip}\n{end}'');if
    [ -z "$endpoint_pods" ];then health_status="Unhealthy";echo "Error: Endpoint for
    service \`"$service"\` does not have any running pods"; echo "Next Steps:\n- Inspect
    Container Restarts in Namespace \`"$NAMESPACE"\` \n- Inspect Pending Pods In Namespace
    \`"$NAMESPACE"\`\n- Inspect Failed Pods In Namespace \`"$NAMESPACE"\`";else echo
    "Endpoint Pod:";echo "$endpoint_pods";health_status="Healthy";fi;fi;done<<<"$backend_services";echo
    "Health Status: $health_status";echo "------------";done'
  doc_links: '

    - [Kubernetes Ingress](https://kubernetes.io/docs/concepts/services-networking/ingress/){:target="_blank"}

    - [Kubernetes Namespace](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/){:target="_blank"}

    - [Backend Services in Kubernetes](https://kubernetes.io/docs/concepts/services-networking/service/){:target="_blank"}

    - [Kubernetes Pods](https://kubernetes.io/docs/concepts/workloads/pods/){:target="_blank"}'
  explanation: This command gathers information about the ingresses in a Kubernetes
    namespace and checks the health status of their associated backend services, including
    if the appropriate pods and endpoints are running and healthy.
  multi_line_details: "\n# Set the value of NAMESPACE and CONTEXT to use in the command\n\
    NAMESPACE=\"${NAMESPACE}\"\nCONTEXT=\"${CONTEXT}\"\n\n# Get a list of ingresses\
    \ in the specified namespace and context\ningresses=$(kubectl get ingress -n \"\
    $NAMESPACE\" --context \"$CONTEXT\" -o jsonpath='{range .items[*]}{.metadata.name}{\"\
    \\n\"}{end}')\n\n# Iterate over each ingress and retrieve its backend services\n\
    for ingress in $ingresses; do\n  echo \"Ingress: $ingress\"\n  health_status=\"\
    NA\"\n  backend_services=$(kubectl get ingress \"$ingress\" -n \"$NAMESPACE\"\
    \ --context \"$CONTEXT\" -o jsonpath='{range .spec.rules[*].http.paths[*]}{.backend.service.name}{\"\
    |\"}{.backend.service.port.number}{\"\\n\"}{end}')\n  \n  # Iterate over each\
    \ backend service and perform health checks\n  while IFS='|' read -r service port;\
    \ do\n    echo \"Backend Service: $service, Port: $port\"\n    \n    # Check if\
    \ the service exists\n    target_ports=$(kubectl get service \"$service\" -n \"\
    $NAMESPACE\" --context \"$CONTEXT\" -o jsonpath=\"{.spec.ports[?(@.port==$port)].targetPort}\"\
    )\n    service_exists=$(kubectl get service \"$service\" -n \"$NAMESPACE\" --context\
    \ \"$CONTEXT\" -ojsonpath='{.metadata.name}')\n    \n    # If the service does\
    \ not exist, set health status to 'Unhealthy'\n    if [ -z \"$service_exists\"\
    \ ]; then\n      health_status=\"Unhealthy\"\n      echo \"Error: Service $service\
    \ does not exist\"\n      echo \"Next Step: Check namespace $NAMESPACE for service\
    \ name $service.\"\n      continue\n    else\n      # Extract selectors and check\
    \ for matching deployment, statefulset, or daemonset\n      selectors=$(kubectl\
    \ get svc \"$service\" -n \"$NAMESPACE\" --context \"$CONTEXT\" -o jsonpath='{.spec.selector}')\n\
    \      label_selector=\"\"\n      \n      # Construct label selector from selectors\
    \ of the service\n      for key in $(echo $selectors | jq -r 'keys[]'); do \n\
    \        value=$(echo $selectors | jq -r --arg key \"$key\" '.[$key]')\n     \
    \   label_selector=\"${label_selector}${key}=${value},\"\n      done\n      \n\
    \      label_selector=${label_selector::-1}\n      found_owner=0\n      \n   \
    \   # Iterate over deployment, statefulset, and daemonset to find matching owners\n\
    \      for kind in deployment statefulset daemonset; do\n        matching_owners=$(kubectl\
    \ get $kind -n \"$NAMESPACE\" --context \"$CONTEXT\" -l \"$label_selector\" -o\
    \ jsonpath='{.items[*].metadata.name}')\n        \n        if [ -n \"$matching_owners\"\
    \ ]; then\n          for owner in $matching_owners; do\n            echo \"Owner\
    \ Kind: $kind\"\n            echo \"Owner Name: $owner\"\n            found_owner=1\n\
    \          done\n        fi\n      done\n      \n      # If no matching owner\
    \ is found, set health status to 'Unhealthy'\n      if [ \"$found_owner\" == 0\
    \ ]; then\n        health_status=\"Unhealthy\"\n        echo \"Error: No matching\
    \ deployment, statefulset, or daemonset found to match label selector \\`\"$label_selector\"\
    \\`\"\n        echo \"Next Steps:\\n- Check namespace \\`\"$NAMESPACE\"\\` for\
    \ deployment, statefulset, or daemonset with labels that match \\`\"$label_selector\"\
    \\`\"\n      fi\n      \n      port_found=\"No\"\n      associated_pods=$(kubectl\
    \ get pods -n \"$NAMESPACE\" --context \"$CONTEXT\" -l \"$label_selector\" -o\
    \ jsonpath='{.items[*].metadata.name}')\n      \n      # Iterate over associated\
    \ pods and check for matching target port\n      for pod in $associated_pods;\
    \ do\n        container_ports=$(kubectl get pod \"$pod\" -n \"$NAMESPACE\" --context\
    \ \"$CONTEXT\" -o jsonpath='{.spec.containers[*].ports[*].containerPort}')\n \
    \       \n        for target_port in $target_ports; do\n          if echo \"$container_ports\"\
    \ | grep -wq \"$target_port\"; then\n            port_found=\"Yes\"\n        \
    \    break\n          fi\n        done\n      done\n      \n      # Set health\
    \ status based on the availability of target ports in associated pods\n      if\
    \ [ \"$port_found\" = \"No\" ]; then\n        health_status=\"Unhealthy\"\n  \
    \      echo \"Warning: targetPort $target_ports of service $service is not found\
    \ as a containerPort in associated pods\"\n      else\n        health_status=\"\
    Healthy\"\n      fi\n      \n      endpoint_pods=$(kubectl get endpoints \"$service\"\
    \ -n \"$NAMESPACE\" --context \"$CONTEXT\" -ojsonpath='{range .subsets[*].addresses[*]}-\
    \ Pod Name: {.targetRef.name}\\n Pod IP: {.ip}\\n{end}')\n      \n      # Perform\
    \ health checks on endpoint pods\n      if [ -z \"$endpoint_pods\" ]; then\n \
    \       health_status=\"Unhealthy\"\n        echo \"Error: Endpoint for service\
    \ \\`\"$service\"\\` does not have any running pods\"\n        echo \"Next Steps:\\\
    n- Inspect Container Restarts in Namespace \\`\"$NAMESPACE\"\\` \\n- Inspect Pending\
    \ Pods In Namespace \\`\"$NAMESPACE\"\\`\\n- Inspect Failed Pods In Namespace\
    \ \\`\"$NAMESPACE\"\\`\"\n      else\n        echo \"Endpoint Pod:\"\n       \
    \ echo \"$endpoint_pods\"\n        health_status=\"Healthy\"\n      fi\n    fi\n\
    \  done <<<\"$backend_services\"\n  \n  # Display the overall health status of\
    \ the ingress\n  echo \"Health Status: $health_status\"\n  echo \"------------\"\
    \ndone\n"
  name: fetch_ingress_object_health_in_namespace_namespace
  when_is_it_useful: '1. Investigating a website outage: When a website hosted in
    a Kubernetes cluster experiences downtime or errors, the DevOps or Site Reliability
    Engineer may use this command to check the health status of the ingresses and
    their associated backend services to identify any issues.


    2. Debugging high error rates: If an application running in a Kubernetes cluster
    is experiencing high error rates, the engineer may use this command to inspect
    the health of the backend services and determine if any pods or endpoints are
    not functioning properly.


    3. Troubleshooting performance issues: When performance degradation is observed
    in an application deployed on Kubernetes, the engineer may use this command to
    verify the health status of the backend services and ensure that all necessary
    pods and endpoints are operational.


    4. Monitoring for proactive maintenance: As part of regular monitoring and maintenance
    activities, the engineer may use this command to periodically check the health
    status of the ingresses and their associated backend services to detect any potential
    issues before they impact the application.


    5. Validating a new deployment: Prior to rolling out a new deployment or making
    changes to the configuration of the ingresses or backend services, the engineer
    may use this command to validate the health status and ensure that the deployment
    will not cause any disruptions.'
- command: 'NAMESPACE="${NAMESPACE}";CONTEXT="${CONTEXT}";ingresses=$(kubectl get
    ingress -n "$NAMESPACE" --context "$CONTEXT" -o jsonpath=''{range .items[*]}{.metadata.name}{"\n"}{end}'');for
    ingress in $ingresses;do echo "Ingress: $ingress";health_status="NA";backend_services=$(kubectl
    get ingress "$ingress" -n "$NAMESPACE" --context "$CONTEXT" -o jsonpath=''{range
    .spec.rules[*].http.paths[*]}{.backend.service.name}{"|"}{.backend.service.port.number}{"\n"}{end}'');while
    IFS=''|'' read -r service port;do echo "Backend Service: $service, Port: $port";target_ports=$(kubectl
    get service "$service" -n "$NAMESPACE" --context "$CONTEXT" -o jsonpath="{.spec.ports[?(@.port==$port)].targetPort}");service_exists=$(kubectl
    get service "$service" -n "$NAMESPACE" --context "$CONTEXT" -ojsonpath=''{.metadata.name}'');if
    [ -z "$service_exists" ];then health_status="Unhealthy";echo "Error: Service $service
    does not exist";echo "Next Step: Check namespace $NAMESPACE for service name $service.";continue;else
    selectors=$(kubectl get svc "$service" -n "$NAMESPACE" --context "$CONTEXT" -o
    jsonpath=''{.spec.selector}'');label_selector="";for key in $(echo $selectors
    | jq -r ''keys[]'');do value=$(echo $selectors | jq -r --arg key "$key" ''.[$key]'');label_selector="\${label_selector}\${key}=\${value},";done;label_selector=\${label_selector::-1};found_owner=0;for
    kind in deployment statefulset daemonset;do matching_owners=$(kubectl get $kind
    -n "$NAMESPACE" --context "$CONTEXT" -l "$label_selector" -o jsonpath=''{.items[*].metadata.name}'');if
    [ -n "$matching_owners" ];then for owner in $matching_owners;do echo "Owner Kind:
    $kind";echo "Owner Name: $owner";found_owner=1;done;fi;done;if [ "$found_owner"
    == 0 ];then echo "Error: No matching deployment, statefulset, or daemonset found
    to match label selector \`"$label_selector"\`";echo "Next Steps:\n- Check namespace
    \`"$NAMESPACE"\` for deployment, statefulset, or daemonset with labels that match
    \`"$label_selector"\`";fi;port_found="No";associated_pods=$(kubectl get pods -n
    "$NAMESPACE" --context "$CONTEXT" -l "$label_selector" -o jsonpath=''{.items[*].metadata.name}'');for
    pod in $associated_pods;do container_ports=$(kubectl get pod "$pod" -n "$NAMESPACE"
    --context "$CONTEXT" -o jsonpath=''{.spec.containers[*].ports[*].containerPort}'');for
    target_port in $target_ports;do if echo "$container_ports" | grep -wq "$target_port";then
    port_found="Yes";break;fi;done;done;if [ "$port_found" = "No" ];then health_status="Unhealthy";echo
    "Warning: targetPort $target_ports of service $service is not found as a containerPort
    in associated pods";else health_status="Healthy";fi;endpoint_pods=$(kubectl get
    endpoints "$service" -n "$NAMESPACE" --context "$CONTEXT" -ojsonpath=''{range
    .subsets[*].addresses[*]}- Pod Name: {.targetRef.name}\n Pod IP: {.ip}\n{end}'');if
    [ -z "$endpoint_pods" ];then health_status="Unhealthy";echo "Error: Endpoint for
    service \`"$service"\` does not have any running pods"; echo "Next Steps:\n- Inspect
    Container Restarts in Namespace \`"$NAMESPACE"\` \n- Inspect Pending Pods In Namespace
    \`"$NAMESPACE"\`\n- Inspect Failed Pods In Namespace \`"$NAMESPACE"\`";else echo
    "Endpoint Pod:";echo "$endpoint_pods";health_status="Healthy";fi;fi;done<<<"$backend_services";echo
    "Health Status: $health_status";echo "------------";done'
  doc_links: '

    - [Kubernetes Ingress](https://kubernetes.io/docs/concepts/services-networking/ingress/){:target="_blank"}

    - [Kubernetes Namespace](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/){:target="_blank"}

    - [Backend Services in Kubernetes](https://kubernetes.io/docs/concepts/services-networking/service/){:target="_blank"}

    - [Kubernetes Pods](https://kubernetes.io/docs/concepts/workloads/pods/){:target="_blank"}'
  explanation: This command gathers information about the ingresses in a Kubernetes
    namespace and checks the health status of their associated backend services, including
    if the appropriate pods and endpoints are running and healthy.
  multi_line_details: "\n# Set the value of NAMESPACE and CONTEXT to use in the command\n\
    NAMESPACE=\"${NAMESPACE}\"\nCONTEXT=\"${CONTEXT}\"\n\n# Get a list of ingresses\
    \ in the specified namespace and context\ningresses=$(kubectl get ingress -n \"\
    $NAMESPACE\" --context \"$CONTEXT\" -o jsonpath='{range .items[*]}{.metadata.name}{\"\
    \\n\"}{end}')\n\n# Iterate over each ingress and retrieve its backend services\n\
    for ingress in $ingresses; do\n  echo \"Ingress: $ingress\"\n  health_status=\"\
    NA\"\n  backend_services=$(kubectl get ingress \"$ingress\" -n \"$NAMESPACE\"\
    \ --context \"$CONTEXT\" -o jsonpath='{range .spec.rules[*].http.paths[*]}{.backend.service.name}{\"\
    |\"}{.backend.service.port.number}{\"\\n\"}{end}')\n  \n  # Iterate over each\
    \ backend service and perform health checks\n  while IFS='|' read -r service port;\
    \ do\n    echo \"Backend Service: $service, Port: $port\"\n    \n    # Check if\
    \ the service exists\n    target_ports=$(kubectl get service \"$service\" -n \"\
    $NAMESPACE\" --context \"$CONTEXT\" -o jsonpath=\"{.spec.ports[?(@.port==$port)].targetPort}\"\
    )\n    service_exists=$(kubectl get service \"$service\" -n \"$NAMESPACE\" --context\
    \ \"$CONTEXT\" -ojsonpath='{.metadata.name}')\n    \n    # If the service does\
    \ not exist, set health status to 'Unhealthy'\n    if [ -z \"$service_exists\"\
    \ ]; then\n      health_status=\"Unhealthy\"\n      echo \"Error: Service $service\
    \ does not exist\"\n      echo \"Next Step: Check namespace $NAMESPACE for service\
    \ name $service.\"\n      continue\n    else\n      # Extract selectors and check\
    \ for matching deployment, statefulset, or daemonset\n      selectors=$(kubectl\
    \ get svc \"$service\" -n \"$NAMESPACE\" --context \"$CONTEXT\" -o jsonpath='{.spec.selector}')\n\
    \      label_selector=\"\"\n      \n      # Construct label selector from selectors\
    \ of the service\n      for key in $(echo $selectors | jq -r 'keys[]'); do \n\
    \        value=$(echo $selectors | jq -r --arg key \"$key\" '.[$key]')\n     \
    \   label_selector=\"${label_selector}${key}=${value},\"\n      done\n      \n\
    \      label_selector=${label_selector::-1}\n      found_owner=0\n      \n   \
    \   # Iterate over deployment, statefulset, and daemonset to find matching owners\n\
    \      for kind in deployment statefulset daemonset; do\n        matching_owners=$(kubectl\
    \ get $kind -n \"$NAMESPACE\" --context \"$CONTEXT\" -l \"$label_selector\" -o\
    \ jsonpath='{.items[*].metadata.name}')\n        \n        if [ -n \"$matching_owners\"\
    \ ]; then\n          for owner in $matching_owners; do\n            echo \"Owner\
    \ Kind: $kind\"\n            echo \"Owner Name: $owner\"\n            found_owner=1\n\
    \          done\n        fi\n      done\n      \n      # If no matching owner\
    \ is found, set health status to 'Unhealthy'\n      if [ \"$found_owner\" == 0\
    \ ]; then\n        health_status=\"Unhealthy\"\n        echo \"Error: No matching\
    \ deployment, statefulset, or daemonset found to match label selector \\`\"$label_selector\"\
    \\`\"\n        echo \"Next Steps:\\n- Check namespace \\`\"$NAMESPACE\"\\` for\
    \ deployment, statefulset, or daemonset with labels that match \\`\"$label_selector\"\
    \\`\"\n      fi\n      \n      port_found=\"No\"\n      associated_pods=$(kubectl\
    \ get pods -n \"$NAMESPACE\" --context \"$CONTEXT\" -l \"$label_selector\" -o\
    \ jsonpath='{.items[*].metadata.name}')\n      \n      # Iterate over associated\
    \ pods and check for matching target port\n      for pod in $associated_pods;\
    \ do\n        container_ports=$(kubectl get pod \"$pod\" -n \"$NAMESPACE\" --context\
    \ \"$CONTEXT\" -o jsonpath='{.spec.containers[*].ports[*].containerPort}')\n \
    \       \n        for target_port in $target_ports; do\n          if echo \"$container_ports\"\
    \ | grep -wq \"$target_port\"; then\n            port_found=\"Yes\"\n        \
    \    break\n          fi\n        done\n      done\n      \n      # Set health\
    \ status based on the availability of target ports in associated pods\n      if\
    \ [ \"$port_found\" = \"No\" ]; then\n        health_status=\"Unhealthy\"\n  \
    \      echo \"Warning: targetPort $target_ports of service $service is not found\
    \ as a containerPort in associated pods\"\n      else\n        health_status=\"\
    Healthy\"\n      fi\n      \n      endpoint_pods=$(kubectl get endpoints \"$service\"\
    \ -n \"$NAMESPACE\" --context \"$CONTEXT\" -ojsonpath='{range .subsets[*].addresses[*]}-\
    \ Pod Name: {.targetRef.name}\\n Pod IP: {.ip}\\n{end}')\n      \n      # Perform\
    \ health checks on endpoint pods\n      if [ -z \"$endpoint_pods\" ]; then\n \
    \       health_status=\"Unhealthy\"\n        echo \"Error: Endpoint for service\
    \ \\`\"$service\"\\` does not have any running pods\"\n        echo \"Next Steps:\\\
    n- Inspect Container Restarts in Namespace \\`\"$NAMESPACE\"\\` \\n- Inspect Pending\
    \ Pods In Namespace \\`\"$NAMESPACE\"\\`\\n- Inspect Failed Pods In Namespace\
    \ \\`\"$NAMESPACE\"\\`\"\n      else\n        echo \"Endpoint Pod:\"\n       \
    \ echo \"$endpoint_pods\"\n        health_status=\"Healthy\"\n      fi\n    fi\n\
    \  done <<<\"$backend_services\"\n  \n  # Display the overall health status of\
    \ the ingress\n  echo \"Health Status: $health_status\"\n  echo \"------------\"\
    \ndone\n"
  name: fetch_ingress_object_health_in_namespace_namespace
  when_is_it_useful: '1. Investigating a website outage: When a website hosted in
    a Kubernetes cluster experiences downtime or errors, the DevOps or Site Reliability
    Engineer may use this command to check the health status of the ingresses and
    their associated backend services to identify any issues.


    2. Debugging high error rates: If an application running in a Kubernetes cluster
    is experiencing high error rates, the engineer may use this command to inspect
    the health of the backend services and determine if any pods or endpoints are
    not functioning properly.


    3. Troubleshooting performance issues: When performance degradation is observed
    in an application deployed on Kubernetes, the engineer may use this command to
    verify the health status of the backend services and ensure that all necessary
    pods and endpoints are operational.


    4. Monitoring for proactive maintenance: As part of regular monitoring and maintenance
    activities, the engineer may use this command to periodically check the health
    status of the ingresses and their associated backend services to detect any potential
    issues before they impact the application.


    5. Validating a new deployment: Prior to rolling out a new deployment or making
    changes to the configuration of the ingresses or backend services, the engineer
    may use this command to validate the health status and ensure that the deployment
    will not cause any disruptions.'
- command: 'CONTEXT="${CONTEXT}"; NAMESPACE="${NAMESPACE}"; kubectl --context "${CONTEXT}"
    --namespace "${NAMESPACE}" get ingress -o json | jq -r ''.items[] | select(.status.loadBalancer.ingress)
    | .metadata.name as \$name | .status.loadBalancer.ingress[0].ip as \$ingress_ip
    | .spec.rules[]?.http.paths[]? | "\($name) \($ingress_ip) \(.backend.service.name)
    \(.backend.service.port.number)"'' | while read -r ingress_name ingress_ip service_name
    service_port; do kubectl --context "${CONTEXT}" --namespace "${NAMESPACE}" get
    svc "$service_name" -o json | jq --arg ingress_name "$ingress_name" --arg ingress_ip
    "$ingress_ip" --arg service_name "$service_name" --arg service_port "$service_port"
    -r ''if .spec.type == "LoadBalancer" then .status.loadBalancer.ingress[0].ip as
    $service_ip | if $ingress_ip and $service_ip and $service_ip != $ingress_ip then
    "WARNING: Ingress \($ingress_name) IP (\($ingress_ip)) differs from Service \($service_name)
    IP (\($service_ip))" else "OK: Ingress \($ingress_name) - Service \($service_name)
    is of type LoadBalancer with IP (\($service_ip))" end else "OK: Ingress \($ingress_name)
    - Service \($service_name) is of type \(.spec.type) on port \($service_port)"
    end''; done'
  doc_links: '

    - [Kubectl Overview](https://kubernetes.io/docs/reference/kubectl/overview/){:target="_blank"}

    - [Ingress in Kubernetes](https://kubernetes.io/docs/concepts/services-networking/ingress/){:target="_blank"}

    - [Services in Kubernetes](https://kubernetes.io/docs/concepts/services-networking/service/){:target="_blank"}'
  explanation: This command is using kubectl to retrieve information about ingresses
    and services in a Kubernetes cluster. It's checking for any discrepancies between
    the IP addresses of the ingresses and services, and it will provide warnings if
    there are any differences.
  multi_line_details: "\n# Set the context and namespace for kubectl\nCONTEXT=\"${CONTEXT}\"\
    \nNAMESPACE=\"${NAMESPACE}\"\n\n# Get the ingress information in JSON format and\
    \ filter it to extract specific fields\nkubectl --context \"${CONTEXT}\" --namespace\
    \ \"${NAMESPACE}\" get ingress -o json | jq -r '.items[] | select(.status.loadBalancer.ingress)\
    \ | .metadata.name as \\$name | .status.loadBalancer.ingress[0].ip as \\$ingress_ip\
    \ | .spec.rules[]?.http.paths[]? | \"\\($name) \\($ingress_ip) \\(.backend.service.name)\
    \ \\(.backend.service.port.number)\"' |\n  # Read the extracted data into variables\
    \ and process it further\n  while read -r ingress_name ingress_ip service_name\
    \ service_port; do \n    # Get the service information in JSON format and compare\
    \ IPs if the service type is LoadBalancer\n    kubectl --context \"${CONTEXT}\"\
    \ --namespace \"${NAMESPACE}\" get svc \"$service_name\" -o json | jq --arg ingress_name\
    \ \"$ingress_name\" --arg ingress_ip \"$ingress_ip\" --arg service_name \"$service_name\"\
    \ --arg service_port \"$service_port\" -r 'if .spec.type == \"LoadBalancer\" then\
    \ .status.loadBalancer.ingress[0].ip as $service_ip | if $ingress_ip and $service_ip\
    \ and $service_ip != $ingress_ip then \"WARNING: Ingress \\($ingress_name) IP\
    \ (\\($ingress_ip)) differs from Service \\($service_name) IP (\\($service_ip))\"\
    \ else \"OK: Ingress \\($ingress_name) - Service \\($service_name) is of type\
    \ LoadBalancer with IP (\\($service_ip))\" end else \"OK: Ingress \\($ingress_name)\
    \ - Service \\($service_name) is of type \\(.spec.type) on port \\($service_port)\"\
    \ end';\n  done\n"
  name: check_for_ingress_and_service_conflicts_in_namespace_namespace
  when_is_it_useful: '1. Deploying a new application: When deploying a new application
    in a Kubernetes cluster, a DevOps or Site Reliability Engineer may use this command
    to ensure that the ingresses and services are correctly configured and that there
    are no discrepancies between their IP addresses.


    2. Troubleshooting network issues: If there are network connectivity issues between
    ingresses and services in a Kubernetes cluster, a DevOps or Site Reliability Engineer
    may use this command to identify any discrepancies in the IP addresses and troubleshoot
    the issue.


    3. Monitoring for potential security vulnerabilities: This command can be used
    to regularly check for any discrepancies between ingresses and services in a Kubernetes
    cluster, helping to identify potential security vulnerabilities or misconfigurations
    that could pose a risk to the system.


    4. Conducting regular health checks: As part of regular system maintenance, a
    DevOps or Site Reliability Engineer may use this command to conduct routine health
    checks on ingresses and services in a Kubernetes cluster, ensuring that everything
    is functioning as expected.


    5. Investigating CrashLoopBackoff events: In the event of CrashLoopBackoff events
    occurring in a Kubernetes cluster, a DevOps or Site Reliability Engineer may use
    this command to investigate any discrepancies between the IP addresses of ingresses
    and services that could be contributing to the issue.'
- command: 'CONTEXT="${CONTEXT}"; NAMESPACE="${NAMESPACE}"; kubectl --context "${CONTEXT}"
    --namespace "${NAMESPACE}" get ingress -o json | jq -r ''.items[] | select(.status.loadBalancer.ingress)
    | .metadata.name as \$name | .status.loadBalancer.ingress[0].ip as \$ingress_ip
    | .spec.rules[]?.http.paths[]? | "\($name) \($ingress_ip) \(.backend.service.name)
    \(.backend.service.port.number)"'' | while read -r ingress_name ingress_ip service_name
    service_port; do kubectl --context "${CONTEXT}" --namespace "${NAMESPACE}" get
    svc "$service_name" -o json | jq --arg ingress_name "$ingress_name" --arg ingress_ip
    "$ingress_ip" --arg service_name "$service_name" --arg service_port "$service_port"
    -r ''if .spec.type == "LoadBalancer" then .status.loadBalancer.ingress[0].ip as
    $service_ip | if $ingress_ip and $service_ip and $service_ip != $ingress_ip then
    "WARNING: Ingress \($ingress_name) IP (\($ingress_ip)) differs from Service \($service_name)
    IP (\($service_ip))" else "OK: Ingress \($ingress_name) - Service \($service_name)
    is of type LoadBalancer with IP (\($service_ip))" end else "OK: Ingress \($ingress_name)
    - Service \($service_name) is of type \(.spec.type) on port \($service_port)"
    end''; done'
  doc_links: '

    - [Kubectl Overview](https://kubernetes.io/docs/reference/kubectl/overview/){:target="_blank"}

    - [Ingress in Kubernetes](https://kubernetes.io/docs/concepts/services-networking/ingress/){:target="_blank"}

    - [Services in Kubernetes](https://kubernetes.io/docs/concepts/services-networking/service/){:target="_blank"}'
  explanation: This command is using kubectl to retrieve information about ingresses
    and services in a Kubernetes cluster. It's checking for any discrepancies between
    the IP addresses of the ingresses and services, and it will provide warnings if
    there are any differences.
  multi_line_details: "\n# Set the context and namespace for kubectl\nCONTEXT=\"${CONTEXT}\"\
    \nNAMESPACE=\"${NAMESPACE}\"\n\n# Get the ingress information in JSON format and\
    \ filter it to extract specific fields\nkubectl --context \"${CONTEXT}\" --namespace\
    \ \"${NAMESPACE}\" get ingress -o json | jq -r '.items[] | select(.status.loadBalancer.ingress)\
    \ | .metadata.name as \\$name | .status.loadBalancer.ingress[0].ip as \\$ingress_ip\
    \ | .spec.rules[]?.http.paths[]? | \"\\($name) \\($ingress_ip) \\(.backend.service.name)\
    \ \\(.backend.service.port.number)\"' |\n  # Read the extracted data into variables\
    \ and process it further\n  while read -r ingress_name ingress_ip service_name\
    \ service_port; do \n    # Get the service information in JSON format and compare\
    \ IPs if the service type is LoadBalancer\n    kubectl --context \"${CONTEXT}\"\
    \ --namespace \"${NAMESPACE}\" get svc \"$service_name\" -o json | jq --arg ingress_name\
    \ \"$ingress_name\" --arg ingress_ip \"$ingress_ip\" --arg service_name \"$service_name\"\
    \ --arg service_port \"$service_port\" -r 'if .spec.type == \"LoadBalancer\" then\
    \ .status.loadBalancer.ingress[0].ip as $service_ip | if $ingress_ip and $service_ip\
    \ and $service_ip != $ingress_ip then \"WARNING: Ingress \\($ingress_name) IP\
    \ (\\($ingress_ip)) differs from Service \\($service_name) IP (\\($service_ip))\"\
    \ else \"OK: Ingress \\($ingress_name) - Service \\($service_name) is of type\
    \ LoadBalancer with IP (\\($service_ip))\" end else \"OK: Ingress \\($ingress_name)\
    \ - Service \\($service_name) is of type \\(.spec.type) on port \\($service_port)\"\
    \ end';\n  done\n"
  name: check_for_ingress_and_service_conflicts_in_namespace_namespace
  when_is_it_useful: '1. Deploying a new application: When deploying a new application
    in a Kubernetes cluster, a DevOps or Site Reliability Engineer may use this command
    to ensure that the ingresses and services are correctly configured and that there
    are no discrepancies between their IP addresses.


    2. Troubleshooting network issues: If there are network connectivity issues between
    ingresses and services in a Kubernetes cluster, a DevOps or Site Reliability Engineer
    may use this command to identify any discrepancies in the IP addresses and troubleshoot
    the issue.


    3. Monitoring for potential security vulnerabilities: This command can be used
    to regularly check for any discrepancies between ingresses and services in a Kubernetes
    cluster, helping to identify potential security vulnerabilities or misconfigurations
    that could pose a risk to the system.


    4. Conducting regular health checks: As part of regular system maintenance, a
    DevOps or Site Reliability Engineer may use this command to conduct routine health
    checks on ingresses and services in a Kubernetes cluster, ensuring that everything
    is functioning as expected.


    5. Investigating CrashLoopBackoff events: In the event of CrashLoopBackoff events
    occurring in a Kubernetes cluster, a DevOps or Site Reliability Engineer may use
    this command to investigate any discrepancies between the IP addresses of ingresses
    and services that could be contributing to the issue.'
